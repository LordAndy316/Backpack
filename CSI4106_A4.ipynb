{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pbcc9QS1tnBN"
   },
   "source": [
    "**ASSIGNMENT 4**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2Eeke4Z_EkW"
   },
   "source": [
    "1. Group Name: \\\\THE 29TH group\n",
    "   Member Names: \\\\ANDREW HENDERSON Syed Zohaib Ahmed\n",
    "   Member Student Numbers: \\\\300190291, 300136941\n",
    "   Report Title: \\\\ASSIGNMENT 4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RMUnCICdyBbs"
   },
   "source": [
    "**Derived Datasets**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-so3pwbPKTDX"
   },
   "source": [
    "These are the imports used for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "id": "aCWgl6PLKTDY"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CSyg0jjC1jJa"
   },
   "source": [
    "This is the URL for the dataset chosen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "1Xx4qMCLKTDb"
   },
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/syedahmed1674/A4Csi4106/main/reduced_file_cnnnews.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "wg24OUV81Xgm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://raw.githubusercontent.com/syedahmed1674/A4Csi4106/main/reduced_file_cnnnews.csv\n"
     ]
    }
   ],
   "source": [
    "print(url)\n",
    "data = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test to see if we retrieved the data we can print the first few elements with .head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "AQ5nSY1HKTDd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Body</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Theme</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Candy factory didn't evacuate concerned worker...</td>\n",
       "      <td>An eastern Pennsylvania candy factory didn’t e...</td>\n",
       "      <td>An eastern Pennsylvania candy factory didn’t e...</td>\n",
       "      <td>accident investigations, accidents, accidents,...</td>\n",
       "      <td>us</td>\n",
       "      <td>https://edition.cnn.com/2023/10/06/us/pennsylv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Baltimore police ask for public's help identif...</td>\n",
       "      <td>Two shooters were involved in an attack at Mor...</td>\n",
       "      <td>Two shooters were involved in an attack at Mor...</td>\n",
       "      <td>baltimore, brand safety-nsf crime, brand safet...</td>\n",
       "      <td>us</td>\n",
       "      <td>https://edition.cnn.com/2023/10/06/us/morgan-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>An arrest warrant has been issued for a suspec...</td>\n",
       "      <td>Authorities in Pennsylvania say they have issu...</td>\n",
       "      <td>Authorities in Pennsylvania say they have issu...</td>\n",
       "      <td>arrest warrants, arrests, brand safety-nsf cri...</td>\n",
       "      <td>us</td>\n",
       "      <td>https://edition.cnn.com/2023/10/06/us/josh-kru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>115 improperly stored human remains found in C...</td>\n",
       "      <td>An investigation into more than 115 bodies fou...</td>\n",
       "      <td>An investigation into more than 115 bodies fou...</td>\n",
       "      <td>brand safety-nsf death, brand safety-nsf sensi...</td>\n",
       "      <td>us</td>\n",
       "      <td>https://edition.cnn.com/2023/10/06/us/colorado...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Bronx day care provider and 2 others indicted ...</td>\n",
       "      <td>A Bronx day care provider, her husband and his...</td>\n",
       "      <td>A Bronx day care provider, her husband and his...</td>\n",
       "      <td>brand safety-nsf crime, brand safety-nsf death...</td>\n",
       "      <td>us</td>\n",
       "      <td>https://edition.cnn.com/2023/10/05/us/bronx-da...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                              Title  \\\n",
       "0   1  Candy factory didn't evacuate concerned worker...   \n",
       "1   2  Baltimore police ask for public's help identif...   \n",
       "2   3  An arrest warrant has been issued for a suspec...   \n",
       "3   4  115 improperly stored human remains found in C...   \n",
       "4   5  Bronx day care provider and 2 others indicted ...   \n",
       "\n",
       "                                         Description  \\\n",
       "0  An eastern Pennsylvania candy factory didn’t e...   \n",
       "1  Two shooters were involved in an attack at Mor...   \n",
       "2  Authorities in Pennsylvania say they have issu...   \n",
       "3  An investigation into more than 115 bodies fou...   \n",
       "4  A Bronx day care provider, her husband and his...   \n",
       "\n",
       "                                                Body  \\\n",
       "0  An eastern Pennsylvania candy factory didn’t e...   \n",
       "1  Two shooters were involved in an attack at Mor...   \n",
       "2  Authorities in Pennsylvania say they have issu...   \n",
       "3  An investigation into more than 115 bodies fou...   \n",
       "4  A Bronx day care provider, her husband and his...   \n",
       "\n",
       "                                            Keywords Theme  \\\n",
       "0  accident investigations, accidents, accidents,...    us   \n",
       "1  baltimore, brand safety-nsf crime, brand safet...    us   \n",
       "2  arrest warrants, arrests, brand safety-nsf cri...    us   \n",
       "3  brand safety-nsf death, brand safety-nsf sensi...    us   \n",
       "4  brand safety-nsf crime, brand safety-nsf death...    us   \n",
       "\n",
       "                                                Link  \n",
       "0  https://edition.cnn.com/2023/10/06/us/pennsylv...  \n",
       "1  https://edition.cnn.com/2023/10/06/us/morgan-s...  \n",
       "2  https://edition.cnn.com/2023/10/06/us/josh-kru...  \n",
       "3  https://edition.cnn.com/2023/10/06/us/colorado...  \n",
       "4  https://edition.cnn.com/2023/10/05/us/bronx-da...  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y3pycllPKTDd"
   },
   "source": [
    "This is where we create the NLP pipeline. load() will download the correct model (English)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "wQtSi8XuKTDe"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ccqFArDyKTDf"
   },
   "source": [
    "Applying the pipeline to every sentences creates a Document where every word is a Token object.\n",
    "\n",
    "Doc: https://spacy.io/api/doc\n",
    "\n",
    "Token: https://spacy.io/api/token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "WcaeMUL2KTDg"
   },
   "outputs": [],
   "source": [
    "#Apply nlp pipeline to the column that has your sentences.\n",
    "data['tokenized'] = data['Body'].apply(nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jHRfZ2uEKTDh"
   },
   "source": [
    "A Token object has many attributes such as part-of-speech (pos_), lemma (lemma_), etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "qw0a_2ySyUo2"
   },
   "outputs": [],
   "source": [
    "#create empty dataframes that will store the derived datasets\n",
    "\n",
    "derived_dataset1 = pd.DataFrame(columns = ['Class', 'pos'])\n",
    "derived_dataset2 = pd.DataFrame(columns = ['Class', 'pos-np'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function 'get_pos' is designed to extract specific parts of speech (POS) from a given sentence, focusing on the desired POS tags specified by 'wanted_pos.' This is done to isolate and collect words that fall under the chosen POS categories, which can be valuable for various natural language processing (NLP) tasks. By extracting and joining these words as a string, the function prepares the text data for further analysis using techniques like CountVectorizer. For example, when conducting sentiment analysis or text classification, selecting and grouping specific POS tags like verbs can help in capturing the essential semantic information within the text, which is crucial for accurate and effective NLP modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "Yeak1tAOKTDi"
   },
   "outputs": [],
   "source": [
    "def get_pos(sentence, wanted_pos): #wanted_pos refers to the desired pos tagging\n",
    "    verbs = []\n",
    "    for token in sentence:\n",
    "        if token.pos_ in wanted_pos:\n",
    "            verbs.append(token.lemma_) # lemma returns a number. lemma_ return a string\n",
    "    return ' '.join(verbs) # return value is as a string and not a list for countVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "147NRzwKKTDj"
   },
   "outputs": [],
   "source": [
    "#We use the above function to fetch all the verbs. We store this information in our first derived dataset\n",
    "derived_dataset1['pos'] = data['tokenized'].apply(lambda sent : get_pos(sent, ['VERB']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify the first few contents of derived_dataset1 by using .head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "G_bUg_fVKTDk"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>evacuate say smell leave injure announce base ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>involve injure confirm ask identify see walk c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>say issue suspect kill advocate identify consi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>find store offer take say find go say have nee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>indict expose include die say indict accord sa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Class                                                pos\n",
       "0   NaN  evacuate say smell leave injure announce base ...\n",
       "1   NaN  involve injure confirm ask identify see walk c...\n",
       "2   NaN  say issue suspect kill advocate identify consi...\n",
       "3   NaN  find store offer take say find go say have nee...\n",
       "4   NaN  indict expose include die say indict accord sa..."
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "derived_dataset1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AuGv-NnfKTDj"
   },
   "source": [
    "The code is performing named entity extraction and selected parts-of-speech tagging to preprocess and structure textual data. This preprocessing is essential in natural language processing (NLP) tasks, where understanding the context and content of text is critical. Extracting named entities helps identify and categorize specific entities within the text, providing valuable information for tasks like information retrieval and entity recognition. Similarly, isolating certain parts of speech like nouns, verbs, and adjectives allows for a more focused analysis, aiding in sentiment analysis, summarization, and other NLP applications that rely on the semantic and syntactic characteristics of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "NR7AdW0MfXO6"
   },
   "outputs": [],
   "source": [
    "def extract_entities_and_pos(text):\n",
    "\n",
    "    doc = nlp(text)\n",
    "\n",
    "\n",
    "    named_entities = []\n",
    "    selected_pos_tags = []\n",
    "\n",
    "\n",
    "    for token in doc:\n",
    "        # Check if the token is a named entity\n",
    "        if token.ent_type:\n",
    "            named_entities.append((token.text, token.ent_type))\n",
    "\n",
    "\n",
    "        if token.pos_ in ['NOUN', 'VERB', 'ADJ']:\n",
    "            selected_pos_tags.append((token.text, token.pos))\n",
    "\n",
    "    return named_entities, selected_pos_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify the elements of derived_dataset2 through .head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>pos-np</th>\n",
       "      <th>named_entities</th>\n",
       "      <th>selected_pos_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(Pennsylvania, 384), (March, 391), (seven, 39...</td>\n",
       "      <td>[(eastern, 84), (candy, 92), (factory, 92), (e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(Two, 397), (Morgan, 383), (State, 383), (Uni...</td>\n",
       "      <td>[(shooters, 92), (involved, 100), (attack, 92)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(Pennsylvania, 384), (Josh, 380), (Kruger, 38...</td>\n",
       "      <td>[(Authorities, 92), (say, 100), (issued, 100),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(more, 397), (than, 397), (115, 397), (Colora...</td>\n",
       "      <td>[(investigation, 92), (more, 84), (bodies, 92)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(Bronx, 384), (four, 397), (1, 391), (-, 391)...</td>\n",
       "      <td>[(day, 92), (care, 92), (provider, 92), (husba...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Class pos-np                                     named_entities  \\\n",
       "0   NaN    NaN  [(Pennsylvania, 384), (March, 391), (seven, 39...   \n",
       "1   NaN    NaN  [(Two, 397), (Morgan, 383), (State, 383), (Uni...   \n",
       "2   NaN    NaN  [(Pennsylvania, 384), (Josh, 380), (Kruger, 38...   \n",
       "3   NaN    NaN  [(more, 397), (than, 397), (115, 397), (Colora...   \n",
       "4   NaN    NaN  [(Bronx, 384), (four, 397), (1, 391), (-, 391)...   \n",
       "\n",
       "                                   selected_pos_tags  \n",
       "0  [(eastern, 84), (candy, 92), (factory, 92), (e...  \n",
       "1  [(shooters, 92), (involved, 100), (attack, 92)...  \n",
       "2  [(Authorities, 92), (say, 100), (issued, 100),...  \n",
       "3  [(investigation, 92), (more, 84), (bodies, 92)...  \n",
       "4  [(day, 92), (care, 92), (provider, 92), (husba...  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "derived_dataset2['named_entities'], derived_dataset2['selected_pos_tags'] = zip(*data['tokenized'].apply(extract_entities_and_pos))\n",
    "derived_dataset2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1GhniwHtzfQt"
   },
   "source": [
    "**Perform Classification Task**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function, 'runtest,' assesses a machine learning model's performance. It fits the 'model' to the training data, uses it to predict labels for the test data, calculates accuracy, generates a comprehensive classification report with precision, recall, and F1-score metrics for each class, and ultimately returns the accuracy and classification report as evaluation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runtest(model, X_train, X_test, y_train, y_test):\n",
    "    # Fit the 'model' to the training data.\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Use the trained model to make predictions on the test data.\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate the accuracy of the model by comparing predicted labels ('y_pred') to true labels ('y_test').\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Generate a classification report that includes metrics such as precision, recall, and F1-score for each class.\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    # Return the accuracy and classification report as results of the model evaluation.\n",
    "    return accuracy, report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MODEL 1: MLP Model on DATASET 1 with no parameters**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning the 'data' dataset to the variable 'dataset' for convenience.\n",
    "dataset = data\n",
    "\n",
    "# Splitting the dataset into training and testing sets, with 80% for training and 20% for testing.\n",
    "# We're using the columns 'Title', 'Description', 'Body', 'Keywords', and 'Link' as features ('X') \n",
    "# and the 'Theme' column as the target ('y').\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset[['Title', 'Description', 'Body', 'Keywords', 'Link']], dataset['Theme'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Creating a TF-IDF vectorizer with a maximum of 1000 features.\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "\n",
    "# Transforming the 'Body' text data in the training set into TF-IDF vectors.\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train['Body'])\n",
    "\n",
    "# Transforming the 'Body' text data in the testing set into TF-IDF vectors using the same vectorizer.\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test['Body'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The provided code is performing a machine learning experiment to assess the performance of a Multi-Layer Perceptron (MLP) classifier on a text classification task. It uses the 'runtest' function to train the MLP model on the TF-IDF transformed training data ('X_train_tfidf') and evaluates its performance on the TF-IDF transformed testing data ('X_test_tfidf') using the ground truth labels 'y_train' and 'y_test.' The accuracy score of 0.79 is a measure of how accurately the model predicted the class labels of the test data. An accuracy of 0.79 indicates that the model correctly predicted approximately 79% of the test data's labels. This accuracy is a significant metric as it quantifies the model's overall performance; higher accuracy values indicate better classification results, while lower values suggest room for improvement. Therefore, an accuracy of 0.79 suggests that the MLP classifier performed reasonably well on the given text classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.88      0.86      0.87        43\n",
      "entertainment       0.62      0.62      0.62        21\n",
      "       health       0.86      0.94      0.90        33\n",
      "     opinions       0.78      0.64      0.71        28\n",
      "     politics       0.85      0.81      0.83        27\n",
      "        sport       0.79      0.92      0.85        25\n",
      "        style       0.00      0.00      0.00         6\n",
      "       travel       0.00      0.00      0.00         1\n",
      "           us       0.67      0.53      0.59        19\n",
      "      weather       0.95      1.00      0.98        20\n",
      "        world       0.71      0.83      0.77        60\n",
      "\n",
      "     accuracy                           0.79       283\n",
      "    macro avg       0.65      0.65      0.65       283\n",
      " weighted avg       0.77      0.79      0.78       283\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "mlp_model = MLPClassifier()\n",
    "a,z = runtest(mlp_model,X_train_tfidf, X_test_tfidf, y_train, y_test)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code  serves the purpose of assessing the performance of a machine learning model, specifically an MLP classifier, using K-Fold cross-validation. K-Fold cross-validation is beneficial because it divides the dataset into 'n' subsets (in this case, 10 subsets due to 'n_splits=10') and iteratively uses one of these subsets as the test set while training the model on the remaining data. This process is repeated 10 times (controlled by 'n_splits=10') so that each subset serves as the test set once. The results, in the form of accuracy scores for each fold, are averaged and provide a more robust estimate of the model's performance, reducing the risk of overfitting to a specific train-test split. The 'shuffle=True' parameter adds randomness by shuffling the data before splitting, further ensuring a more representative evaluation. The printed accuracy score, along with its standard deviation, summarizes how well the MLP classifier generalizes to unseen data, offering a more reliable assessment of its effectiveness in the real-world scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.784 (0.071)\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=10, random_state=5, shuffle=True)\n",
    "scores = cross_val_score(mlp_model, X_test_tfidf, y_pred_mlp, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MODEL 2: MLP Model 2 on DATASET 1, with parameters (hidden_layer_sizes=(64, 32), max_iter=1000, random_state=42)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning the 'data' dataset to the variable 'dataset' for convenience.\n",
    "dataset = data\n",
    "\n",
    "# Splitting the dataset into training and testing sets:\n",
    "# - Features ('X_train' and 'X_test') consist of columns 'Title', 'Description', 'Body', 'Keywords', and 'Link'.\n",
    "# - The target ('y_train' and 'y_test') is represented by the 'Theme' column.\n",
    "# - We allocate 20% of the data for testing, with a fixed random seed (random_state=42) for reproducibility.\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset[['Title', 'Description', 'Body', 'Keywords', 'Link']], dataset['Theme'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Creating a TF-IDF (Term Frequency-Inverse Document Frequency) vectorizer with a maximum of 1000 features.\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "\n",
    "# Transforming the 'Body' text data in the training set into TF-IDF vectors using the vectorizer.\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train['Body'])\n",
    "\n",
    "# Transforming the 'Body' text data in the testing set into TF-IDF vectors using the same vectorizer.\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test['Body'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code initializes an MLP (Multi-Layer Perceptron) classifier named 'mod2' with specific parameters. The choice of these parameters is motivated by a desire to optimize model performance while considering computational efficiency. 'hidden_layer_sizes=(64, 32)' defines a two-layer architecture that balances model complexity and computational resources. 'max_iter=1000' sets the maximum number of training iterations to ensure effective learning, while 'random_state=42' ensures result reproducibility. The code then uses the 'runtest' function to train 'mod2' on TF-IDF transformed training data and evaluate its performance on the testing data. This parameter selection strategy aims to strike a balance between model capacity, training effectiveness, and consistent results, providing a robust assessment of 'mod2's suitability for text classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.86      0.88      0.87        43\n",
      "entertainment       0.63      0.57      0.60        21\n",
      "       health       0.89      0.94      0.91        33\n",
      "     opinions       0.80      0.57      0.67        28\n",
      "     politics       0.73      0.81      0.77        27\n",
      "        sport       0.82      0.92      0.87        25\n",
      "        style       0.00      0.00      0.00         6\n",
      "       travel       0.00      0.00      0.00         1\n",
      "           us       0.56      0.53      0.54        19\n",
      "      weather       0.95      1.00      0.98        20\n",
      "        world       0.73      0.80      0.76        60\n",
      "\n",
      "     accuracy                           0.78       283\n",
      "    macro avg       0.63      0.64      0.63       283\n",
      " weighted avg       0.76      0.78      0.77       283\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "mod2 = MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=1000, random_state=42)\n",
    "b,z = runtest(mod2,X_train_tfidf, X_test_tfidf, y_train, y_test)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code employs K-Fold cross-validation to assess the performance of the 'mod2' MLP classifier on a text classification task. The choice of using K-Fold cross-validation is crucial because it allows for a more robust evaluation of the model's generalization capabilities by repeatedly splitting the dataset into training and testing subsets, ensuring that every data point serves as both training and testing data at some point. With 'n_splits=10,' it divides the data into 10 subsets, enhancing reliability. The 'shuffle=True' option introduces randomness by shuffling the data before splitting, reducing the risk of any order-related bias. The 'cross_val_score' function computes accuracy scores for each fold, and the final result, along with its standard deviation, is printed. This approach offers a comprehensive and dependable evaluation of 'mod2's performance, providing insights into how well the model is expected to generalize to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.767 (0.069)\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=10, random_state=5, shuffle=True)\n",
    "scores = cross_val_score(mod2, X_test_tfidf, y_pred_mlp, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MODEL 3: MLP Model 3 on DATASET 1, with parameters: (hidden_layer_sizes=(128, 64), max_iter=1000, random_state=42)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning the 'data' dataset to the variable 'dataset' for convenience.\n",
    "dataset = data\n",
    "\n",
    "# Splitting the dataset into training and testing sets:\n",
    "# - Features ('X_train' and 'X_test') consist of columns 'Title', 'Description', 'Body', 'Keywords', and 'Link'.\n",
    "# - The target ('y_train' and 'y_test') is represented by the 'Theme' column.\n",
    "# - We allocate 20% of the data for testing, with a fixed random seed (random_state=42) for reproducibility.\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset[['Title', 'Description', 'Body', 'Keywords', 'Link']], dataset['Theme'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Creating a TF-IDF (Term Frequency-Inverse Document Frequency) vectorizer with a maximum of 1000 features.\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "\n",
    "# Transforming the 'Body' text data in the training set into TF-IDF vectors using the vectorizer.\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train['Body'])\n",
    "\n",
    "# Transforming the 'Body' text data in the testing set into TF-IDF vectors using the same vectorizer.\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test['Body'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code continues the machine learning experiment with an MLP classifier, 'mod3,' for text classification. Initially, the architecture was set to '(64, 32)' to balance model complexity and resource efficiency. However, in this iteration, it has been adjusted to '(128, 64)' to explore a deeper neural network with more neurons, potentially capturing more intricate patterns in the data. The 'max_iter=1000' parameter ensures effective learning, and 'random_state=42' ensures result reproducibility. The code utilizes the 'runtest' function to train 'mod3' on TF-IDF transformed training data and evaluate its performance on the testing data. This parameter adjustment reflects an experimentation-driven decision to explore a more complex model architecture, aiming to further enhance 'mod3's effectiveness in text classification and evaluating its impact on model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.88      0.84      0.86        43\n",
      "entertainment       0.59      0.62      0.60        21\n",
      "       health       0.89      0.97      0.93        33\n",
      "     opinions       0.85      0.61      0.71        28\n",
      "     politics       0.79      0.85      0.82        27\n",
      "        sport       0.79      0.88      0.83        25\n",
      "        style       1.00      0.17      0.29         6\n",
      "       travel       0.00      0.00      0.00         1\n",
      "           us       0.53      0.53      0.53        19\n",
      "      weather       0.95      1.00      0.98        20\n",
      "        world       0.74      0.82      0.78        60\n",
      "\n",
      "     accuracy                           0.79       283\n",
      "    macro avg       0.73      0.66      0.66       283\n",
      " weighted avg       0.79      0.79      0.78       283\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "mod3 = MLPClassifier(hidden_layer_sizes=(128, 64), max_iter=1000, random_state=42)\n",
    "c,z = runtest(mod3,X_train_tfidf, X_test_tfidf, y_train, y_test)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code employs K-Fold cross-validation to evaluate the performance of the 'mod3' MLP classifier with an architecture of '(128, 64)' on a text classification task. The choice of K-Fold cross-validation with 'n_splits=10' ensures a robust assessment by repeatedly dividing the data into ten subsets for training and testing, reducing the risk of overfitting to a specific split. The 'shuffle=True' option introduces randomness in data splitting for more reliable results. The 'cross_val_score' function calculates accuracy scores for each fold of the cross-validation process, and the final result, with an accuracy of 0.788, is printed. This accuracy score indicates that 'mod3' correctly predicted approximately 78.8% of the test data's labels, offering a quantitative measure of its performance in text classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.788 (0.056)\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=10, random_state=5, shuffle=True)\n",
    "scores = cross_val_score(mod3, X_test_tfidf, y_pred_mlp, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MODEL 4: Logistic Regression Model on DATASET 1:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This code snippet performs text classification using a Logistic Regression model. First, the 'logistic_regression_model' is initialized, then it's trained on the TF-IDF transformed training data 'X_train_tfidf' and corresponding labels 'y_train.' Following training, it predicts labels for the test data using 'X_test_tfidf' and stores the predictions in 'y_pred_logistic.' The code calculates the accuracy score by comparing the true test labels 'y_test' with the predicted labels and stores it in 'd.' Finally, it generates and prints a comprehensive classification report that includes metrics such as precision, recall, and F1-score. This entire process evaluates the Logistic Regression model's performance on text classification tasks, providing insights into its accuracy and predictive capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     business       0.88      0.86      0.87        43\n",
      "entertainment       0.71      0.57      0.63        21\n",
      "       health       0.76      0.88      0.82        33\n",
      "     opinions       0.62      0.29      0.39        28\n",
      "     politics       0.67      0.74      0.70        27\n",
      "        sport       0.85      0.88      0.86        25\n",
      "        style       0.00      0.00      0.00         6\n",
      "       travel       0.00      0.00      0.00         1\n",
      "           us       1.00      0.11      0.19        19\n",
      "      weather       0.95      1.00      0.98        20\n",
      "        world       0.57      0.90      0.70        60\n",
      "\n",
      "     accuracy                           0.72       283\n",
      "    macro avg       0.64      0.57      0.56       283\n",
      " weighted avg       0.73      0.72      0.69       283\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_model = LogisticRegression()\n",
    "logistic_regression_model.fit(X_train_tfidf, y_train)\n",
    "d = accuracy_score(y_test, y_pred_logistic)\n",
    "y_pred_logistic = logistic_regression_model.predict(X_test_tfidf)\n",
    "print(\"Logistic Regression Classification Report:\\n\", classification_report(y_test, y_pred_logistic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This code snippet employs K-Fold cross-validation to assess the performance of a Logistic Regression model on a text classification task. By setting 'n_splits=4,' it divides the data into four subsets for training and testing, ensuring a robust evaluation of the model's generalization abilities while reducing the risk of overfitting to specific data splits. The 'shuffle=True' parameter introduces randomness in data splitting for more reliable results. The 'cross_val_score' function calculates accuracy scores for each fold of the cross-validation process, and the final printed accuracy score, along with its standard deviation, provides a quantifiable measure of the Logistic Regression model's performance in text classification. This approach ensures a more comprehensive and dependable assessment of the model's effectiveness on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.625 (0.037)\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=4, random_state=5, shuffle=True)\n",
    "scores = cross_val_score(logistic_regression_model, X_test_tfidf, y_pred_mlp, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We repeat the experiment from models 5-12 with the MLP Models 1-3 and Logistic Regression Model for derived dataset 1 and derived dataset 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MODEL 5: MLP Model 1 on DERIVED DATASET 1, with no parameters:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the 'derived_dataset1' into training and testing sets:\n",
    "# - Features ('X_train' and 'X_test') consist of a single column 'pos'.\n",
    "# - The target ('y_train' and 'y_test') is represented by the 'Theme' column from the original 'dataset'.\n",
    "# - We allocate 20% of the data for testing, with a fixed random seed (random_state=42) for reproducibility.\n",
    "X_train, X_test, y_train, y_test = train_test_split(derived_dataset1[['pos']], dataset['Theme'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Creating a TF-IDF (Term Frequency-Inverse Document Frequency) vectorizer with a maximum of 1000 features.\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "\n",
    "# Transforming the 'pos' text data in the training set into TF-IDF vectors using the vectorizer.\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train['pos'])\n",
    "\n",
    "# Transforming the 'pos' text data in the testing set into TF-IDF vectors using the same vectorizer.\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test['pos'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.62      0.74      0.67        43\n",
      "entertainment       0.71      0.57      0.63        21\n",
      "       health       0.87      0.82      0.84        33\n",
      "     opinions       0.89      0.61      0.72        28\n",
      "     politics       0.59      0.70      0.64        27\n",
      "        sport       0.73      0.76      0.75        25\n",
      "        style       0.00      0.00      0.00         6\n",
      "       travel       0.00      0.00      0.00         1\n",
      "           us       0.69      0.47      0.56        19\n",
      "      weather       0.91      1.00      0.95        20\n",
      "        world       0.61      0.72      0.66        60\n",
      "\n",
      "     accuracy                           0.70       283\n",
      "    macro avg       0.60      0.58      0.58       283\n",
      " weighted avg       0.70      0.70      0.69       283\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "d1mod1 = MLPClassifier()\n",
    "e,z = runtest(d1mod1,X_train_tfidf, X_test_tfidf, y_train, y_test)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MODEL 6: MLP Model 2 on DERIVED DATASET 1, with parameters: (hidden_layer_sizes=(64, 32), max_iter=1000, random_state=42)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.59      0.77      0.67        43\n",
      "entertainment       0.67      0.48      0.56        21\n",
      "       health       0.87      0.82      0.84        33\n",
      "     opinions       0.95      0.68      0.79        28\n",
      "     politics       0.58      0.70      0.63        27\n",
      "        sport       0.62      0.72      0.67        25\n",
      "        style       0.00      0.00      0.00         6\n",
      "       travel       0.00      0.00      0.00         1\n",
      "           us       0.67      0.42      0.52        19\n",
      "      weather       0.91      1.00      0.95        20\n",
      "        world       0.66      0.70      0.68        60\n",
      "\n",
      "     accuracy                           0.69       283\n",
      "    macro avg       0.59      0.57      0.57       283\n",
      " weighted avg       0.69      0.69      0.68       283\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "d1mod2 = MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=1000, random_state=42)\n",
    "f,z = runtest(d1mod2,X_train_tfidf, X_test_tfidf, y_train, y_test)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MODEL 7: MLP Model 3 on DERIVED DATASET 1, with parameters: (hidden_layer_sizes=(128, 64), max_iter=1000, random_state=42)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.64      0.74      0.69        43\n",
      "entertainment       0.69      0.43      0.53        21\n",
      "       health       0.87      0.82      0.84        33\n",
      "     opinions       0.86      0.64      0.73        28\n",
      "     politics       0.55      0.67      0.60        27\n",
      "        sport       0.65      0.80      0.71        25\n",
      "        style       0.00      0.00      0.00         6\n",
      "       travel       0.00      0.00      0.00         1\n",
      "           us       0.69      0.47      0.56        19\n",
      "      weather       0.91      1.00      0.95        20\n",
      "        world       0.59      0.67      0.62        60\n",
      "\n",
      "     accuracy                           0.68       283\n",
      "    macro avg       0.59      0.57      0.57       283\n",
      " weighted avg       0.68      0.68      0.67       283\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "d1mod3 = MLPClassifier(hidden_layer_sizes=(128, 64), max_iter=1000, random_state=42)\n",
    "g,z = runtest(d1mod3,X_train_tfidf, X_test_tfidf, y_train, y_test)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MODEL 8: Logistic Regression Model on DERIVED DATASET 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.64      0.74      0.69        43\n",
      "entertainment       0.69      0.43      0.53        21\n",
      "       health       0.87      0.82      0.84        33\n",
      "     opinions       0.86      0.64      0.73        28\n",
      "     politics       0.55      0.67      0.60        27\n",
      "        sport       0.65      0.80      0.71        25\n",
      "        style       0.00      0.00      0.00         6\n",
      "       travel       0.00      0.00      0.00         1\n",
      "           us       0.69      0.47      0.56        19\n",
      "      weather       0.91      1.00      0.95        20\n",
      "        world       0.59      0.67      0.62        60\n",
      "\n",
      "     accuracy                           0.68       283\n",
      "    macro avg       0.59      0.57      0.57       283\n",
      " weighted avg       0.68      0.68      0.67       283\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_model = LogisticRegression()\n",
    "h,z = runtest(mod,X_train_tfidf, X_test_tfidf, y_train, y_test)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis**: In the evaluation on derived dataset 1, we observed differing accuracy scores among the models. MLP Model 1, which utilized default parameters, achieved the highest accuracy of 0.7. Hypothetically, this might be because the dataset's characteristics align well with the default settings, and additional complexity introduced by customized parameters could have led to overfitting or underfitting. On the other hand, MLP Model 2, with a simpler architecture of (64, 32), and MLP Model 3, employing a more complex architecture of (128, 64), achieved slightly lower accuracies of 0.69 and 0.68, respectively. The hypothesis here is that Model 2 might be slighly underutilizing its capacity, while Model 3's greater complexity may have caused it to overfit the data. The Logistic Regression model performed similarly to MLP Model 3, suggesting that a simpler linear model was effective for this dataset. Ultimately, this highlights the importance of carefully tailored architecture parameters based on dataset characteristics to optimize model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>pos-np</th>\n",
       "      <th>named_entities</th>\n",
       "      <th>selected_pos_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(Pennsylvania, 384), (March, 391), (seven, 39...</td>\n",
       "      <td>[(eastern, 84), (candy, 92), (factory, 92), (e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(Two, 397), (Morgan, 383), (State, 383), (Uni...</td>\n",
       "      <td>[(shooters, 92), (involved, 100), (attack, 92)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(Pennsylvania, 384), (Josh, 380), (Kruger, 38...</td>\n",
       "      <td>[(Authorities, 92), (say, 100), (issued, 100),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(more, 397), (than, 397), (115, 397), (Colora...</td>\n",
       "      <td>[(investigation, 92), (more, 84), (bodies, 92)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(Bronx, 384), (four, 397), (1, 391), (-, 391)...</td>\n",
       "      <td>[(day, 92), (care, 92), (provider, 92), (husba...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Class pos-np                                     named_entities  \\\n",
       "0   NaN    NaN  [(Pennsylvania, 384), (March, 391), (seven, 39...   \n",
       "1   NaN    NaN  [(Two, 397), (Morgan, 383), (State, 383), (Uni...   \n",
       "2   NaN    NaN  [(Pennsylvania, 384), (Josh, 380), (Kruger, 38...   \n",
       "3   NaN    NaN  [(more, 397), (than, 397), (115, 397), (Colora...   \n",
       "4   NaN    NaN  [(Bronx, 384), (four, 397), (1, 391), (-, 391)...   \n",
       "\n",
       "                                   selected_pos_tags  \n",
       "0  [(eastern, 84), (candy, 92), (factory, 92), (e...  \n",
       "1  [(shooters, 92), (involved, 100), (attack, 92)...  \n",
       "2  [(Authorities, 92), (say, 100), (issued, 100),...  \n",
       "3  [(investigation, 92), (more, 84), (bodies, 92)...  \n",
       "4  [(day, 92), (care, 92), (provider, 92), (husba...  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "derived_dataset2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MODEL 9: MLP Model 1 on DERIVED DATASET 2, with no parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the 'derived_dataset2' into training and testing sets:\n",
    "# - Features ('X_train' and 'X_test') consist of columns 'pos-np', 'named_entities', and 'selected_pos_tags'.\n",
    "# - The target ('y_train' and 'y_test') is represented by the 'Theme' column from the original 'dataset'.\n",
    "# - We allocate 20% of the data for testing, with a fixed random seed (random_state=42) for reproducibility.\n",
    "X_train, X_test, y_train, y_test = train_test_split(derived_dataset2[['pos-np', 'named_entities', 'selected_pos_tags']], dataset['Theme'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Creating a TF-IDF (Term Frequency-Inverse Document Frequency) vectorizer with a maximum of 1000 features.\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "\n",
    "# Transforming the 'pos-np' text data in the training set into TF-IDF vectors using the vectorizer.\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train['pos-np'])\n",
    "\n",
    "# Transforming the 'pos-np' text data in the testing set into TF-IDF vectors using the same vectorizer.\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test['pos-np'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.88      0.84      0.86        43\n",
      "entertainment       0.59      0.62      0.60        21\n",
      "       health       0.89      0.97      0.93        33\n",
      "     opinions       0.85      0.61      0.71        28\n",
      "     politics       0.79      0.85      0.82        27\n",
      "        sport       0.79      0.88      0.83        25\n",
      "        style       1.00      0.17      0.29         6\n",
      "       travel       0.00      0.00      0.00         1\n",
      "           us       0.53      0.53      0.53        19\n",
      "      weather       0.95      1.00      0.98        20\n",
      "        world       0.74      0.82      0.78        60\n",
      "\n",
      "     accuracy                           0.79       283\n",
      "    macro avg       0.73      0.66      0.66       283\n",
      " weighted avg       0.79      0.79      0.78       283\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "d2mod1 = MLPClassifier()\n",
    "i,z = runtest(d2mod1,X_train_tfidf, X_test_tfidf, y_train, y_test)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MODEL 10: MLP Model 2 on DERIVED DATASET 2, with parameters: (hidden_layer_sizes=(64, 32), max_iter=2000, random_state=33)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.88      0.84      0.86        43\n",
      "entertainment       0.67      0.57      0.62        21\n",
      "       health       0.84      0.94      0.89        33\n",
      "     opinions       0.75      0.64      0.69        28\n",
      "     politics       0.81      0.81      0.81        27\n",
      "        sport       0.77      0.92      0.84        25\n",
      "        style       0.00      0.00      0.00         6\n",
      "       travel       0.00      0.00      0.00         1\n",
      "           us       0.58      0.58      0.58        19\n",
      "      weather       1.00      1.00      1.00        20\n",
      "        world       0.74      0.80      0.77        60\n",
      "\n",
      "     accuracy                           0.78       283\n",
      "    macro avg       0.64      0.65      0.64       283\n",
      " weighted avg       0.77      0.78      0.77       283\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d2mod2 = MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=2000, random_state=33)\n",
    "j,z = runtest(d2mod2,X_train_tfidf, X_test_tfidf, y_train, y_test)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MODEL 11: MLP Model 3 on DERIVED DATASET 2, with parameters: (hidden_layer_sizes=(128, 64), max_iter=2000, random_state=33)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.82      0.86      0.84        43\n",
      "entertainment       0.67      0.57      0.62        21\n",
      "       health       0.86      0.91      0.88        33\n",
      "     opinions       0.76      0.68      0.72        28\n",
      "     politics       0.88      0.78      0.82        27\n",
      "        sport       0.79      0.92      0.85        25\n",
      "        style       0.00      0.00      0.00         6\n",
      "       travel       0.00      0.00      0.00         1\n",
      "           us       0.56      0.53      0.54        19\n",
      "      weather       0.91      1.00      0.95        20\n",
      "        world       0.72      0.78      0.75        60\n",
      "\n",
      "     accuracy                           0.77       283\n",
      "    macro avg       0.63      0.64      0.63       283\n",
      " weighted avg       0.76      0.77      0.76       283\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d2mod3 = MLPClassifier(hidden_layer_sizes=(128, 64), max_iter=2000, random_state=33)\n",
    "k,z = runtest(d2mod3,X_train_tfidf, X_test_tfidf, y_train, y_test)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MODEL 12: Logistic Regression Model on DERIVED DATASET 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.88      0.84      0.86        43\n",
      "entertainment       0.59      0.62      0.60        21\n",
      "       health       0.89      0.97      0.93        33\n",
      "     opinions       0.85      0.61      0.71        28\n",
      "     politics       0.79      0.85      0.82        27\n",
      "        sport       0.79      0.88      0.83        25\n",
      "        style       1.00      0.17      0.29         6\n",
      "       travel       0.00      0.00      0.00         1\n",
      "           us       0.53      0.53      0.53        19\n",
      "      weather       0.95      1.00      0.98        20\n",
      "        world       0.74      0.82      0.78        60\n",
      "\n",
      "     accuracy                           0.79       283\n",
      "    macro avg       0.73      0.66      0.66       283\n",
      " weighted avg       0.79      0.79      0.78       283\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_model = LogisticRegression()\n",
    "l,z = runtest(mod,X_train_tfidf, X_test_tfidf, y_train, y_test)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis** In the evaluation on derived dataset 2, we observed that MLP Model 1, with default parameters, achieved the highest accuracy of 0.79, while MLP Model 2, with a simpler architecture of (64, 32), and MLP Model 3, employing a more complex architecture of (128, 64), achieved slightly lower accuracies of 0.78 and 0.77, respectively. Remarkably, the Logistic Regression model also achieved an accuracy of 0.79, indicating that a simpler linear model performed comparably well on this dataset. Hypothetically, Model 1 may have matched the dataset's characteristics effectively without additional parameter tuning, while Model 2 and Model 3's customizations could have introduced some degree of overfitting or underfitting. The close proximity of accuracy scores among these models suggests that the dataset might not be significantly affected by architectural complexities. This dataset exhibits a consistency in model performance compared to derived dataset 1, emphasizing the influence of dataset-specific characteristics on model outcomes and the potential effectiveness of simpler models when warranted.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GRAPHICAL ANALYSIS:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = ['D1M1', 'D1M2', 'D1M3', 'D1L1', 'DD1M1', 'DD1M2','DD1M3','DD1L1','DD2M1','DD2M2','DD2M3','DD2L1']\n",
    "values = [a, b, c, d, e, f,g,h,i,j,k,l]\n",
    "\n",
    "for iz in range(len(values)):\n",
    "    values[iz] = round(values[iz], 3)\n",
    "# Create the bar graph\n",
    "plt.figure(figsize=(10, 5))  # Adjust the width and height as needed\n",
    "\n",
    "# Create a bar graph with the specified bar width\n",
    "plt.bar(labels, values)\n",
    "for iss, value in enumerate(values):\n",
    "    plt.text(iss, value, str(value), ha='center', va='bottom')\n",
    "# Add a title and labels\n",
    "plt.title('Bar Graph of Twelve Models Cases')\n",
    "plt.xlabel('Result lists')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "# Display the graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis:** When examining the performance across different datasets, it's evident that the initial full dataset yields the highest accuracy results, reaching up to 0.792. However, in the derived dataset 1, which involves extracting only nouns and limiting the dataset for testing, we observe a slight dip in accuracy. This decline may be attributed to the reduction in data and the specific focus on nouns, which can result in a loss of context. In contrast, derived dataset 2, which includes three entities for comparison, exhibits improved accuracy. Interestingly, there is a noteworthy consistency between the Linear Regression model and MLP models across these datasets, suggesting that the simpler linear model can perform on par with more complex neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References:** \n",
    "https://carpentries-incubator.github.io/machine-learning-novice-sklearn/06-neural-networks/index.html\n",
    "                                                         \n",
    "https://austingwalters.com/classify-sentences-via-a-multilayer-perceptron-mlp/                                                                                                     \n",
    "https://php-ml.readthedocs.io/en/0.5.0/machine-learning/neural-network/multilayer-perceptron-classifier/                                                 \n",
    "https://analyticsindiamag.com/a-beginners-guide-to-scikit-learns-mlpclassifier/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
