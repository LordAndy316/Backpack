{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea1a5edf",
   "metadata": {},
   "source": [
    "Andrew Henderson 300190291\n",
    "group 71\n",
    "Syed Ahmed 300136941\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fc2a51",
   "metadata": {},
   "source": [
    "Citation\n",
    "@article{scikit-learn,\n",
    " title={Scikit-learn: Machine Learning in {P}ython},\n",
    " author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.\n",
    "         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.\n",
    "         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and\n",
    "         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},\n",
    " journal={Journal of Machine Learning Research},\n",
    " volume={12},\n",
    " pages={2825--2830},\n",
    " year={2011}\n",
    "}\n"
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html

https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression

https://www.kaggle.com/datasets/danushkumarv/glass-identification-data-set

https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler

https://scikit-learn.org/stable/modules/naive_bayes.html

https://nitin9809.medium.com/lightgbm-binary-classification-multi-class-classification-regression-using-python-4f22032b36a2


https://forecastegy.com/posts/lightgbm-multiclass-classification-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e442cab",
   "metadata": {},
   "source": [
    "STEP 1 a. The goal of the classification task is to determine the type of glass based on various features, such as refractive index and the percentages of different elements (Sodium, Magnesium, Aluminum, Silicon, Potassium, Calcium, Barium, and Iron). This classification task is essential for applications like glass manufacturing quality control and forensic investigations where identifying the type of glass found at a crime scene or accident site can provide valuable insights. There are seven class types, including window glass, float processed, building windows, vehicle windows, non-float processed, containers, tableware, and headlamps.\n",
    "\n",
    "b. The dataset contains a total of 214 instances, and the classes are imbalanced, with the majority being window glass (163 instances) and float processed (87 instances). There are a total of 10 features, which include refractive index (RI) and the weight percentages of different elements. There is no missing data in this dataset. Each instance is labeled with its type of glass, serving as the target variable for our classification task. This dataset will allow us to explore the relationships between the features and the glass types, enabling us to build logistic regression and Naive Bayes models for accurate classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bfda0498",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import LGBMClassifier\n",
    "import matplotlib.pylab as plt\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b7a901da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    TimeSeriesSplit,\n",
    "    KFold,\n",
    "    StratifiedKFold,\n",
    "    GroupKFold,\n",
    "    StratifiedGroupKFold,\n",
    ")\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from numpy import mean\n",
    "from matplotlib import pyplot\n",
    "from numpy import std\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2da433a",
   "metadata": {},
   "source": [
    "the goal is to ideantify glass types from the elements and properties of a sample of glass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "86b48d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/LordAndy316/Backpack/main/glass.csv\"\n",
    "dataset = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674237bb",
   "metadata": {},
   "source": [
    "Here we Import the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9d61f52e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'RI', 'Na', 'Mg', 'Al', 'Si', 'K', 'Ca', 'Ba', 'Fe',\n",
       "       'Type of glass'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5f883ee9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "      <th>Type of glass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.52101</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1.10</td>\n",
       "      <td>71.78</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.51766</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.51742</td>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1.51596</td>\n",
       "      <td>12.79</td>\n",
       "      <td>3.61</td>\n",
       "      <td>1.62</td>\n",
       "      <td>72.97</td>\n",
       "      <td>0.64</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1.51743</td>\n",
       "      <td>13.30</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.14</td>\n",
       "      <td>73.09</td>\n",
       "      <td>0.58</td>\n",
       "      <td>8.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1.51756</td>\n",
       "      <td>13.15</td>\n",
       "      <td>3.61</td>\n",
       "      <td>1.05</td>\n",
       "      <td>73.24</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1.51918</td>\n",
       "      <td>14.04</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1.37</td>\n",
       "      <td>72.08</td>\n",
       "      <td>0.56</td>\n",
       "      <td>8.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1.51755</td>\n",
       "      <td>13.00</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id       RI     Na    Mg    Al     Si     K    Ca   Ba    Fe  Type of glass\n",
       "0   1  1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.0  0.00              1\n",
       "1   2  1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.0  0.00              1\n",
       "2   3  1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.0  0.00              1\n",
       "3   4  1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.0  0.00              1\n",
       "4   5  1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.0  0.00              1\n",
       "5   6  1.51596  12.79  3.61  1.62  72.97  0.64  8.07  0.0  0.26              1\n",
       "6   7  1.51743  13.30  3.60  1.14  73.09  0.58  8.17  0.0  0.00              1\n",
       "7   8  1.51756  13.15  3.61  1.05  73.24  0.57  8.24  0.0  0.00              1\n",
       "8   9  1.51918  14.04  3.58  1.37  72.08  0.56  8.30  0.0  0.00              1\n",
       "9  10  1.51755  13.00  3.60  1.36  72.99  0.57  8.40  0.0  0.11              1"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be9990e",
   "metadata": {},
   "source": [
    "Here is the first 10 entries of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9554d659",
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_list(string):\n",
    "\n",
    "    string_list = string.strip('[]').split()\n",
    "\n",
    "    float_list = [float(element) for element in string_list]\n",
    "\n",
    "    return float_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "785e7d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4753b33f",
   "metadata": {},
   "source": [
    "Function to find how many times each type occers. this was used to familiarize ourselzes with the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "647d4869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the 'combinations' function from the 'itertools' library.\n",
    "from itertools import combinations\n",
    "\n",
    "# Define a function 'glass_type' that takes the 'data' parameter.\n",
    "def glass_type(data):\n",
    "    # Initialize a counter 'z' to keep track of the occurrences of the specified glass type.\n",
    "    z = 0\n",
    "    # Create a new subset 'glass' from the 'dataset' that only contains rows matching the specified 'data' (glass type).\n",
    "    glass = dataset[dataset['Type of glass'] == data]\n",
    "    \n",
    "    # Loop through each row in the 'glass' subset.\n",
    "    for _, row in glass.iterrows():\n",
    "        # Uncomment the next line to print the 'Type of glass' for each row (optional).\n",
    "        # print(glass['Type of glass'])\n",
    "        # Increment the 'z' counter for each matching row.\n",
    "        z = z + 1\n",
    "    \n",
    "    # Print the type of glass and the number of occurrences in the dataset.\n",
    "    print(\"glass type \", data, \" number of occurrence \", z)\n",
    "    \n",
    "    # Return the 'glass' subset, which contains all rows of the specified glass type.\n",
    "    return glass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7de4d0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glass type  1  number of occurrence  70\n",
      "glass type  2  number of occurrence  76\n",
      "glass type  3  number of occurrence  17\n",
      "glass type  4  number of occurrence  0\n",
      "glass type  5  number of occurrence  13\n",
      "glass type  6  number of occurrence  9\n",
      "glass type  7  number of occurrence  29\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(1,8):\n",
    "    glass_type(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97243fcd",
   "metadata": {},
   "source": [
    "We've implemented a function to identify and analyze data samples falling within specific value ranges for individual columns. This approach helps us explore potential relationships and patterns in the dataset, allowing for a more comprehensive examination of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9142914e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the 'combinations' function from the 'itertools' library (although it's not used in this code).\n",
    "from itertools import combinations\n",
    "\n",
    "# Define a function 'column_split' that takes three parameters: 'col', 'min_freq', and 'max_freq'.\n",
    "def column_split(col, min_freq, max_freq):\n",
    "    # Initialize a list 'gprob' to hold counts for each type of glass.\n",
    "    gprob = [0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    # Initialize a 'total' counter to keep track of the total number of occurrences.\n",
    "    total = 0\n",
    "    \n",
    "    # Create a new subset 'glass' from the 'dataset' that contains rows where the 'col' value falls within the specified range.\n",
    "    glass = dataset[dataset[col] >= min_freq]\n",
    "    glass = glass[glass[col] <= max_freq]\n",
    "    \n",
    "    # Loop through each row in the 'glass' subset.\n",
    "    for _, row in glass.iterrows():\n",
    "        # Extract the type of glass ('Type of glass') as an integer.\n",
    "        g = int(row['Type of glass'])\n",
    "        \n",
    "        # Increment the count for the specific type of glass.\n",
    "        gprob[g] = gprob[g] + 1\n",
    "        # Increment the 'total' counter for each matching row.\n",
    "        total = total + 1\n",
    "    \n",
    "    # Print information about the specified column, frequency range, counts for each glass type, and the total count.\n",
    "    print(col, \" between \", min_freq, \" and \", max_freq, \" number of occurrence \", gprob, \" total number \", total)\n",
    "    \n",
    "    # Return the 'gprob' list, which contains the counts for each type of glass in the specified range.\n",
    "    return gprob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "48afdde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RI  between  1.51  and  1.5159  number of occurrence  [0, 4, 7, 0, 0, 3, 2, 6]  total number  22\n",
      "Na  between  12.72  and  14  number of occurrence  [0, 56, 61, 13, 0, 9, 2, 4]  total number  145\n",
      "Mg  between  3.0  and  8  number of occurrence  [0, 66, 57, 17, 0, 0, 0, 3]  total number  143\n",
      "Al  between  1.25  and  3  number of occurrence  [0, 32, 57, 10, 0, 10, 6, 27]  total number  142\n",
      "Si  between  72.0  and  80  number of occurrence  [0, 55, 66, 13, 0, 10, 9, 26]  total number  179\n",
      "K  between  0.4  and  2  number of occurrence  [0, 49, 59, 11, 0, 7, 0, 5]  total number  131\n",
      "Ba  between  0.1  and  3  number of occurrence  [0, 2, 3, 1, 0, 2, 0, 26]  total number  34\n",
      "Fe  between  0.01  and  0.5  number of occurrence  [0, 25, 32, 5, 0, 1, 0, 6]  total number  69\n",
      "Fe  between  0.01  and  0.05  number of occurrence  [0, 1, 0, 0, 0, 0, 0, 2]  total number  3\n"
     ]
    }
   ],
   "source": [
    "RI = column_split('RI',1.51,1.5159)\n",
    "Na = column_split('Na',12.72,14)\n",
    "Mg =column_split('Mg',3.0,8)\n",
    "Al = column_split('Al',1.25,3)\n",
    "Si = column_split('Si',72.0,80)\n",
    "K = column_split('K',0.4,2)\n",
    "Ba = column_split('Ba',0.10,3)\n",
    "Fe = column_split('Fe',0.01,0.5)\n",
    "Fe = column_split('Fe',0.01,0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9813b246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(RI)\n",
    "np.argmax(Na)\n",
    "np.argmax(Mg)\n",
    "np.argmax(Al)\n",
    "np.argmax(Si)\n",
    "np.argmax(K)\n",
    "np.argmax(Ba)\n",
    "np.argmax(Fe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d542fe0",
   "metadata": {},
   "source": [
    "STEP 2: We created a function to find the ranges for each column, and this allowed us to better understand the data. The ranges of each feature vary, and we visualized them to gain insights into their distributions. During our discussions in class, we learned that attribute normalization can often improve model performance. Given the varying scales of our features, it seems that normalizing the data would be beneficial for our study. This would ensure that each feature contributes equally to the model, preventing some from having undue influence due to their larger magnitude."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd935738",
   "metadata": {},
   "source": [
    "We've taken some time to brainstorm about the attributes for this classification task. The dataset seems to have relevant features like refractive index and the percentages of elements, which should be crucial in classifying the different types of glass. However, we must admit that we're not fully qualified to classify glass types, as we lack expertise in the specific combinations of elements that make up glass. To address this, we need to conduct research to better understand the significance of these features. Additionally, we can explore the attributes through data visualization and analysis to establish whether they seem to influence the classification, even if we lack in-depth domain expertise. This way, we can make more informed decisions about feature selection and engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0f44e7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function 'val_range' that takes two parameters: 'col' and 'gtype'.\n",
    "def val_range(col, gtype):\n",
    "    # Create a subset 'glass' from the 'dataset' containing rows with the specified 'gtype' (type of glass).\n",
    "    glass = dataset[dataset['Type of glass'] == gtype]\n",
    "    \n",
    "    # Initialize variables 'min_value' and 'max_value' to keep track of the minimum and maximum values in the specified column.\n",
    "    min_value = 100  # Initializing 'min_value' with a high value.\n",
    "    max_value = 0    # Initializing 'max_value' with a low value.\n",
    "    \n",
    "    # Loop through each row in the 'glass' subset.\n",
    "    for _, row in glass.iterrows():\n",
    "        # Extract the type of glass ('Type of glass') as an integer.\n",
    "        g = int(row['Type of glass'])\n",
    "        \n",
    "        # Check if the value in the specified column is greater than the current 'max_value'.\n",
    "        if row[col] > max_value:\n",
    "            max_value = row[col]  # Update 'max_value' if a larger value is found.\n",
    "        \n",
    "        # Check if the value in the specified column is less than the current 'min_value'.\n",
    "        if row[col] < min_value:\n",
    "            min_value = row[col]  # Update 'min_value' if a smaller value is found.\n",
    "    \n",
    "    # Return the minimum and maximum values found in the specified column for the given 'gtype'.\n",
    "    return min_value, max_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f0c1c674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71.35, 73.7) (69.81, 74.45) (71.36, 73.01) (69.89, 73.88) (72.37, 75.41) (70.26, 75.18)\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "val_range('Si',1),\n",
    "val_range('Si',2),\n",
    "val_range('Si',3),\n",
    "val_range('Si',5),\n",
    "val_range('Si',6),\n",
    "val_range('Si',7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "23b12283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0, 0.31) (0.0, 0.35) (0.0, 0.37) (0.0, 0.51) (0.0, 0) (0.0, 0.09)\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "val_range('Fe',1),\n",
    "val_range('Fe',2),\n",
    "val_range('Fe',3),\n",
    "val_range('Fe',5),\n",
    "val_range('Fe',6),\n",
    "val_range('Fe',7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f4544187",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset['Fe']\n",
    "#dataset['Type of glass']\n",
    "#clf = LogisticRegression(random_state=0).fit(X, y)\n",
    "#clf.predict(X[:2, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650fabef",
   "metadata": {},
   "source": [
    "Analysis on the occurance of BA between ranges from 0.01 to 2.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1b483e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ba  between  0.01  and  2.98  number of occurrence  [0, 3, 5, 1, 0, 2, 0, 26]  total number  37\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 3, 5, 1, 0, 2, 0, 26]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low,high = val_range('Ba',7)\n",
    "\n",
    "column_split('Ba',low+0.01,high+0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c064c23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_y(data):\n",
    "    X = data.drop('Type of glass', axis=1)\n",
    "    y = data['Type of glass']\n",
    "\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d570b92",
   "metadata": {},
   "source": [
    "Training the modles on the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6dca53c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset\n",
    "#X = data.drop('Type of glass', axis=1)\n",
    "#y = data['Type of glass']\n",
    "X,y=get_X_y(data)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889ead8e",
   "metadata": {},
   "source": [
    "A function to test our models against "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e60e677d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function 'runtest' that takes a machine learning 'model' and training/test data.\n",
    "def runtest(model, X_train, X_test, y_train, y_test):\n",
    "    # Fit the 'model' to the training data.\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Use the trained model to make predictions on the test data.\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate the predicted probabilities for each class in the test data.\n",
    "    y_prob = model.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate the accuracy of the model by comparing predicted labels ('y_pred') to true labels ('y_test').\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Calculate the log loss, which measures the performance of the model's predicted probabilities.\n",
    "    logloss = log_loss(y_test, y_prob)\n",
    "    \n",
    "    # Generate a classification report that includes metrics such as precision, recall, and F1-score for each class.\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    # Return the accuracy, log loss, and classification report as results of the model evaluation.\n",
    "    return accuracy, logloss, report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b59cf4",
   "metadata": {},
   "source": [
    "Here are our lightgbm model that we are using "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "287451fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMClassifier(learning_rate=0.1, n_estimators=100, num_leaves=31)\n",
    "model.fit(X_train, y_train)\n",
    "a,l,r = runtest(model,X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8afd6f46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accruacy  0.813953488372093 log loss  0.5032886499965298\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.91      0.80        11\n",
      "           2       0.89      0.57      0.70        14\n",
      "           3       0.60      1.00      0.75         3\n",
      "           5       1.00      1.00      1.00         4\n",
      "           6       1.00      0.67      0.80         3\n",
      "           7       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.81        43\n",
      "   macro avg       0.85      0.86      0.83        43\n",
      "weighted avg       0.84      0.81      0.81        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"accruacy \",a,\"log loss \",l)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee39ef4",
   "metadata": {},
   "source": [
    "STEP 3:  For our dataset, it's essential to consider the nature of the features. They primarily consist of continuous attributes, and to prepare the data for modeling, we encoded them accordingly. For logistic regression, which expects continuous attributes, we applied one-hot encoding for discrete attributes. On the other hand, for Naive Bayes, we noticed in our class discussions that this classifier generally expects discrete attributes. However, in scikit-learn, there are options like  GaussianNB.  GaussianNB assumes a Gaussian distribution for continuous attributes. Our decision depended on the nature of our data, that classifier best suits our classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c055e492",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifer = GaussianNB()\n",
    "classifer.fit(X_train, y_train)\n",
    "a,l,r = runtest(classifer,X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d1316bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accruacy  0.813953488372093 log loss  0.5032886499965298\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.91      0.80        11\n",
      "           2       0.89      0.57      0.70        14\n",
      "           3       0.60      1.00      0.75         3\n",
      "           5       1.00      1.00      1.00         4\n",
      "           6       1.00      0.67      0.80         3\n",
      "           7       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.81        43\n",
      "   macro avg       0.85      0.86      0.83        43\n",
      "weighted avg       0.84      0.81      0.81        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sc1 = round(a, 3)\n",
    "print(\"accruacy \",a,\"log loss \",l)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb3bd9e",
   "metadata": {},
   "source": [
    "Step 4: Naive Bayes Model Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23c9be2",
   "metadata": {},
   "source": [
    "Step 4: Logistic Regression Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "438196af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "      \n",
    "    \n",
    "clf = LogisticRegression(solver='saga', max_iter=5000) \n",
    "\n",
    "q,w,e = runtest(clf,X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3f3b8ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accruacy  1.0 log loss  0.1110390149856804\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        11\n",
      "           2       1.00      1.00      1.00        14\n",
      "           3       1.00      1.00      1.00         3\n",
      "           5       1.00      1.00      1.00         4\n",
      "           6       1.00      1.00      1.00         3\n",
      "           7       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        43\n",
      "   macro avg       1.00      1.00      1.00        43\n",
      "weighted avg       1.00      1.00      1.00        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sc2 = round(q, 3)\n",
    "print(\"accruacy \",q,\"log loss \",w)\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9c7a79",
   "metadata": {},
   "source": [
    "Step 5: In our evaluation using precision and recall measures for the multi-class problem, we compared both micro and macro averages. The micro-average provided a higher score due to imbalanced class distribution in our dataset. It gave more weight to the majority class, which led to inflated overall precision and recall. On the other hand, the macro-average, which treats each class equally, gave a more balanced view of our model's performance across all classes. The differences between micro and macro averages highlighted the impact of class imbalances in our dataset, and this information is crucial in understanding how well our model performs for individual classes and as a whole."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1b0473",
   "metadata": {},
   "source": [
    "STEP 5: We employed K-Fold cross-validation to train, test, and evaluate our two models. In our code, we set up a 10-fold cross-validation using the KFold method with a random state for reproducibility and data shuffling for better randomness. We used this to assess the performance of our models and ensure robustness in the evaluation process. By applying this method, we could obtain a more comprehensive view of how well our models generalize to unseen data, and in the end, we printed the accuracy results as a mean and standard deviation of the cross-validation scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "26c3657e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.976 (0.032)\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=10, random_state=5, shuffle=True)\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9466d390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.991 (0.019)\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=10, random_state=5, shuffle=True)\n",
    "scores = cross_val_score(clf, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "db6191b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.823 (0.057)\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=10, random_state=5, shuffle=True)\n",
    "scores = cross_val_score(classifer, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5718d09",
   "metadata": {},
   "source": [
    "K = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabc501f",
   "metadata": {},
   "source": [
    "Step 6: We used Gaussian Naive Bayes for one of our models and adjusted the random state for reproducibility with the code provided. For further model refinement, we experimented with different parameters in two separate iterations. For Naive Bayes, we changed the random state parameter, aiming to observe its impact on model performance. In the case of Logistic Regression, we explored various solvers and tolerance levels. We can observe it is just as effective. Each experiment was carried out in a separate cell with comments specifying the parameters we adjusted. These parameter variations allowed us to gain insights into the model's sensitivity and identify the most effective configurations to enhance classification performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ef11252a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.832 (0.076)\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=10, random_state=3, shuffle=True)\n",
    "scores = cross_val_score(classifer, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "sc3 = round(mean(scores),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbf1867",
   "metadata": {},
   "source": [
    "Reducing the number of states to 3 in our Gaussian Naive Bayes classifier led to a remarkable improvement in model performance, resulting in an accuracy score of 0.832. This positive change can be attributed to the fact that simplifying the model by decreasing the number of states made it more robust and less prone to overfitting our dataset. With fewer states, the model became better aligned with the underlying data distribution, allowing it to make more accurate predictions. Furthermore, the random state optimization played a significant role in achieving this success, as it ensured greater consistency and reproducibility in our results. The combined effect of these adjustments led to a better-performing Gaussian Naive Bayes model for our specific classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6b4818",
   "metadata": {},
   "source": [
    "K = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "32e04fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.818 (0.062)\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=10, random_state=7, shuffle=True)\n",
    "scores = cross_val_score(classifer, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "sc4 = round(mean(scores),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6b8298",
   "metadata": {},
   "source": [
    "Increasing the number of states in our Gaussian Naive Bayes classifier led to a decrease in our model's performance, as evidenced by the accuracy score of 0.818. This decline can be attributed to model over-complexity, where an excessive number of states made the model overly sensitive to noise and minor variations in the data. Consequently, it started to capture random fluctuations rather than the genuine underlying patterns in the dataset, resulting in poorer generalization to new, unseen data. In this case, finding the right balance between model complexity and simplicity is crucial, and it seems that increasing the number of states surpassed the optimal point, causing a drop in overall classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8ca2d7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(solver='newton-cg', max_iter=5000) \n",
    "q,w,e = runtest(clf,X_train, X_test, y_train, y_test)\n",
    "print (q)\n",
    "sc5 = q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c3a1d9",
   "metadata": {},
   "source": [
    "Changing the solver in our Logistic Regression model didn't result in any noticeable impact on the model's performance. The choice of solver affects the optimization technique used during training, but in this particular case, it seems that the default solver or other aspects of the model configuration were more suitable for our dataset. Consequently, the accuracy score remained consistent, suggesting that the solver change wasn't a critical factor influencing our logistic regression model's performance. It's a valuable insight that helps us focus on other aspects of model tuning and optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36110d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "db6f770c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(solver='lbfgs', max_iter=5000) \n",
    "q,w,e = runtest(clf,X_train, X_test, y_train, y_test)\n",
    "print (q)\n",
    "sc6 = q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd58be8",
   "metadata": {},
   "source": [
    "STEP 7: To analysis our results we check: The results from the 2 initial models(logression and naive bayes) are: RESULT1: 1.0 (LR) Result 2: 0.813953488372093(NB) Result 3: 0.832 (NB Modified) Result 4: 0.818(NB Modified) Result 5: 1.0 (LR Modified) Result 6: 1.0 (LR Modified)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c6c5f31a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHFCAYAAAAOmtghAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABCBUlEQVR4nO3deVhVVf/+8fsAMiqoqDgDZjkrJuaUWpmYmtpgYj5PzuVsig2a5pRJmRGpaaYBDWZmWplZSZlppeUApmHWkyao4Jg4hgL794dfzs8jiBymA9v367rOdcU6a+/92QuBu7XXPttiGIYhAAAAk3BydAEAAACFiXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADXCUmJkYWi8XmVblyZd11111au3Ztsdezdu1a9erVS9WrV5erq6vKlSun5s2ba9q0aUpMTCz2erL8/fffslgsmjt3bpEfKy4uTh07dpSPj48sFosiIyOv2/fkyZOaNGmSGjZsKC8vL/n4+Kh+/fp67LHH9Ouvv1r7ZX2f//777wLVljUOeXkV9FiSdOTIEU2fPl3x8fF2bbd//36NHj1at912mzw8POTp6alGjRppypQpOnz4cIHrAkoaF0cXAJRE0dHRql+/vgzDUEpKihYsWKAePXpozZo16tGjR5EfPzMzU4MGDdK7776rrl27Kjw8XAEBAbp48aK2bdum6OhoRUVFKSkpqchrcbTBgwfr/Pnz+vDDD1WhQgUFBATk2O/cuXNq3bq1zp07p6efflrNmjXTxYsX9ccff2j16tWKj49X06ZNJUndu3fXli1bVK1atQLVVq1aNW3ZssWmbeTIkUpNTdWyZcuy9S2oI0eOaMaMGQoICFBQUFCetlm7dq369u2rSpUqafTo0WrevLksFot2796tqKgoffHFF4qLiytwbUCJYgCwio6ONiQZ27Zts2m/cOGC4ebmZjz66KOFdqwLFy5c973Zs2cbkozw8PAc3798+bKxYMGCAh2jIA4cOGBIMl555ZUi2f/VXFxcjBEjRtywX1RUlCHJ2LBhQ47vZ2RkFHZpOerYsaPRqFGjItn3tm3bDElGdHR0nvrv37/f8PLyMpo3b26cPn062/uZmZnGqlWrCrlKwPG4LAXkgbu7u1xdXVWmTBmb9hkzZqhVq1aqWLGivL29dfvtt+vtt9+Wcc3zaAMCAnT//fdr9erVat68udzd3TVjxowcj3Xp0iXNmTNHjRs31sSJE3Ps4+LiolGjRuX5GG+88YY6dOigKlWqyMvLS02aNNGcOXN0+fJlm33cddddaty4sTZv3qzWrVvLw8NDNWrU0PPPP6+MjIwca4mIiFBgYKDKli2rNm3aaOvWrdcfyKvs2bNHvXr1UoUKFeTu7q6goCC988471vezLh2lp6dr0aJF1ss713Py5ElJ158hcXL6/7/urr0s9eeff8rb21uPPPKIzTYbNmyQs7Oznn/++Tyd0/WcOXNGTz31lAIDA+Xq6qoaNWpo3LhxOn/+vE2/lStXqlWrVvLx8ZGnp6fq1KmjwYMHS5I2btyoli1bSpIGDRpkHY/p06df97gRERE6f/68Fi5cKB8fn2zvWywWPfTQQ9avY2Nj1atXL9WsWVPu7u6qW7euhg0bphMnTthsd/z4cT3xxBOqVauW3NzcVLlyZbVr107ffPONTb9vvvlGnTp1kre3tzw9PdWuXTt9++23+doXYA8uSwE5yMjIUHp6ugzD0NGjR/XKK6/o/Pnz6tevn02/v//+W8OGDVPt2rUlSVu3btWYMWN0+PBhTZ061abvzp07tXfvXk2ZMkWBgYHy8vLK8djbt2/X6dOnNWLECLvrvt4x/vrrL/Xr18/6x3XXrl168cUX9fvvvysqKspmHykpKerbt68mTpyomTNn6osvvtCsWbP0zz//aMGCBTZ933jjDdWvX9+6Dub5559Xt27ddODAgRz/mGbZt2+f2rZtqypVqmjevHny9fXV+++/r4EDB+ro0aN65plnrJeO2rRpo969e2vChAm5nnubNm0kSf3799dzzz2n9u3by9fXN0/jduutt2rJkiXq27ev5s2bp7FjxyolJUX9+vVT+/btcw0QN3LhwgV17NhRhw4d0nPPPaemTZvqt99+09SpU7V792598803slgs2rJli0JDQxUaGqrp06fL3d1dBw8e1IYNGyRJt99+u6KjozVo0CBNmTJF3bt3lyTVrFnzusdev369/Pz81Lp16zzV+tdff6lNmzYaOnSofHx89PfffysiIkJ33nmndu/ebQ33jz32mHbu3KkXX3xRt912m06fPq2dO3daA6Ykvf/+++rfv7969eqld955R2XKlNHixYvVpUsXff311+rUqVOe9wXYzdFTR0BJknVZ6tqXm5ubsXDhwly3zcjIMC5fvmzMnDnT8PX1NTIzM63v+fv7G87Ozsa+fftuWMOHH35oSDLefPPNbO9dvnzZ5nW1vB4jq853333XcHZ2Nk6dOmV9r2PHjoYk47PPPrPZ5vHHHzecnJyMgwcPGobx/y9LNWnSxEhPT7f2++WXXwxJxvLly3OtoW/fvoabm5uRmJho0961a1fD09PT5hKKJGPUqFG57i/LzJkzDVdXV+v3LTAw0Bg+fLixa9cum35Z3+cDBw7YtI8YMcJwdXU1tmzZYtxzzz1GlSpVjCNHjuTp2FmuvSwVHh5uODk5ZbvU+fHHHxuSjHXr1hmGYRhz5841JOV4+SiLvZel3N3djdatW9tVf5bMzEzj8uXLxsGDB7P9myhbtqwxbty46257/vx5o2LFikaPHj1s2jMyMoxmzZoZd9xxR573BeQHl6WAHLz77rvatm2btm3bpi+//FIDBgzQqFGjss1cbNiwQffee698fHzk7OysMmXKaOrUqTp58qSOHTtm07dp06a67bbb8l3T6dOnVaZMGZvX9u3b83SMuLg49ezZU76+vtY6+/fvr4yMDP3xxx82fcuVK6eePXvatPXr10+ZmZnatGmTTXv37t3l7Oxsc3xJOnjwYK7nsmHDBnXq1Em1atWyaR84cKAuXLiQbZFuXj3//PNKTExUVFSUhg0bprJly+rNN99UixYttHz58htu/9prr6lRo0a6++67tXHjRr3//vsFXgi8du1aNW7cWEFBQUpPT7e+unTpIovFoo0bN0qS9ZJTnz599NFHHznkLqZjx45p+PDhqlWrllxcXFSmTBn5+/tLkvbu3Wvtd8cddygmJkazZs3S1q1bs13e/Omnn3Tq1CkNGDDA5pwzMzN13333adu2bdZLcjfaF5AfhBsgBw0aNFBwcLCCg4N13333afHixQoJCdEzzzyj06dPS5J++eUXhYSESJKWLFmiH3/8Udu2bdPkyZMlSRcvXrTZZ17/SGZd4ro2IJQrV84auKZNm5bjtjkdIzExUe3bt9fhw4f1+uuva/Pmzdq2bZveeOONHOv08/PLto+qVatKUrZLBdde9nFzc8txn9c6efJkjrVWr149x+PYw8/PT4MGDdKbb76pX3/9Vd9//71cXV315JNP3nBbNzc39evXT//++6+CgoLUuXPnfNeR5ejRo/r111+zBdNy5crJMAzrepYOHTro008/VXp6uvr376+aNWuqcePGeQpl11O7dm0dOHAgT30zMzMVEhKi1atX65lnntG3336rX375xbqG6urv6YoVKzRgwAAtXbpUbdq0UcWKFdW/f3+lpKRYz1mSevfune28X375ZRmGoVOnTuVpX0B+sOYGyKOmTZvq66+/1h9//KE77rhDH374ocqUKaO1a9fK3d3d2u/TTz/NcfvcFsNerUWLFqpQoYI+//xzzZ4929ru7Oys4OBgSVcW4+b1GJ9++qnOnz+v1atXW/8vXNJ1Pysl6w/T1bL+0OR1DcuN+Pr6Kjk5OVv7kSNHJEmVKlUqlONIV0JDSEiIPv30Ux07dkxVqlS5bt89e/Zo6tSpatmypbZt26aIiAiFhYUV6PiVKlWSh4dHtrVNV7+fpVevXurVq5fS0tK0detWhYeHq1+/fgoICLCuKbJHly5dNH/+fG3duvWG62727NmjXbt2KSYmRgMGDLC2/+9//8ux5sjISEVGRioxMVFr1qzRxIkTdezYMX311VfWc5o/f/51j5sVom+0LyA/mLkB8igrDFSuXFnSlSDh4uJic1nm4sWLeu+99wp0HFdXVz399NPas2ePXn755QLtS/r/gSdrVkWSDMPQkiVLcux/9uxZrVmzxqbtgw8+kJOTkzp06FDgeiSpU6dO2rBhgzXMZHn33Xfl6emZ5wWwVzt69KgyMzOztWdkZOjPP/+Up6enypcvf93tz58/r0ceeUQBAQH67rvvNHr0aE2cOFE///yz3bVc7f7779dff/0lX19f62zg1a+cPrfHzc1NHTt2tH7/sz6HJq8zY1nGjx8vLy8v62fvXMswDH3yySeScv53IkmLFy/O9Ri1a9fW6NGj1blzZ+3cuVOS1K5dO5UvX14JCQk5nnNwcLBcXV3ztC8gP5i5AXKwZ88epaenS7pyiWT16tWKjY3Vgw8+qMDAQElX1ptERESoX79+euKJJ3Ty5EnNnTs32x+H/Hj22Wf1+++/a+LEidq0aZNCQ0MVEBCgtLQ07d+/X0uXLpWzs7M8PT1vuK/OnTvL1dVVjz76qJ555hn9+++/WrRokf75558c+/v6+mrEiBFKTEzUbbfdpnXr1mnJkiUaMWKE9ZJZQU2bNk1r167V3XffralTp6pixYpatmyZvvjiC82ZMyfXO62u57333tPixYvVr18/tWzZUj4+Pjp06JCWLl1qvTsppz+oWYYPH67ExET98ssv8vLy0quvvqotW7aob9++iouLyzUY5WbcuHFatWqVOnTooPHjx6tp06bKzMxUYmKi1q9frwkTJqhVq1aaOnWqDh06pE6dOqlmzZo6ffq0Xn/9dZUpU0YdO3aUJN1yyy3y8PDQsmXL1KBBA5UtW1bVq1e3Xs67VmBgoD788EOFhoYqKCjI+iF+kpSQkKCoqCgZhqEHH3xQ9evX1y233KKJEyfKMAxVrFhRn3/+uWJjY232mZqaqrvvvlv9+vVT/fr1rZdLv/rqK+tt5WXLltX8+fM1YMAAnTp1Sr1791aVKlV0/Phx7dq1S8ePH9eiRYvytC8gXxy5mhkoaXK6W8rHx8cICgoyIiIijH///demf1RUlFGvXj3Dzc3NqFOnjhEeHm68/fbb2e7E8ff3N7p37253PWvWrDF69Ohh+Pn5GS4uLka5cuWMoKAgY8KECcbvv/9u0ze3Y3z++edGs2bNDHd3d6NGjRrG008/bXz55ZeGJOO7776z9su602fjxo1GcHCw4ebmZlSrVs147rnnbO7Oyu1D/CQZ06ZNu+G57d692+jRo4fh4+NjuLq6Gs2aNcvxLiDl8W6phIQEY8KECUZwcLBRuXJlw8XFxahQoYLRsWNH47333rPpe+3dUkuWLMnxLqT//e9/hre3t/HAAw/c8PhZcvoQv3PnzhlTpkwx6tWrZ7i6uho+Pj5GkyZNjPHjxxspKSmGYRjG2rVrja5duxo1atQwXF1djSpVqhjdunUzNm/ebLOv5cuXG/Xr1zfKlCmT57H+66+/jJEjRxp169Y13NzcDA8PD6Nhw4ZGWFiYzb/ThIQEo3Pnzka5cuWMChUqGI888oiRmJhoc5x///3XGD58uNG0aVPD29vb8PDwMOrVq2dMmzbNOH/+vM1xv//+e6N79+5GxYoVjTJlyhg1atQwunfvbqxcudLufQH2sBjGNZ82BuCmddddd+nEiRPXXdMDAKUBa24AAICpEG4AAICpcFkKAACYCjM3AADAVAg3AADAVAg3AADAVG66D/HLzMzUkSNHVK5cuTx/HD4AAHAswzB09uxZVa9eXU5Ouc/N3HTh5siRI9meRAwAAEqHpKQk1axZM9c+N124KVeunKQrg+Pt7e3gagAAQF6cOXNGtWrVsv4dz81NF26yLkV5e3sTbgAAKGXysqSEBcUAAMBUCDcAAMBUCDcwrU2bNqlHjx6qXr26LBaLPv300xtu8/3336tFixZyd3dXnTp19OabbxZ9ocBNjJ9T+zFmN0a4gWmdP39ezZo104IFC/LU/8CBA+rWrZvat2+vuLg4Pffccxo7dqxWrVpVxJUCNy9+Tu3HmN3YTfdsqTNnzsjHx0epqaksKL6JWCwWffLJJ3rggQeu2+fZZ5/VmjVrtHfvXmvb8OHDtWvXLm3ZsqUYqgRubvyc2u9mGjN7/n4zcwP8ny1btigkJMSmrUuXLtq+fbsuX77soKoAXI2fU/vdjGNGuAH+T0pKivz8/Gza/Pz8lJ6erhMnTjioKgBX4+fUfjfjmBFugKtc+/kJWVdteVQHUHLwc2q/m23MCDfA/6latapSUlJs2o4dOyYXFxf5+vo6qCoAV+Pn1H4345gRboD/06ZNG8XGxtq0rV+/XsHBwSpTpoyDqgJwNX5O7XczjplDww336qMonTt3TvHx8YqPj5d05XbI+Ph4JSYmSpImTZqk/v37W/sPHz5cBw8eVFhYmPbu3auoqCi9/fbbeuqppxxRPnBT4OfUfoxZHhgOtG7dOmPy5MnGqlWrDEnGJ598kmv//fv3G56ensaTTz5pJCQkGEuWLDHKlCljfPzxx3k+ZmpqqiHJSE1NLWD1KOm+++47Q1K214ABAwzDMIwBAwYYHTt2tNlm48aNRvPmzQ1XV1cjICDAWLRoUfEXDtxE+Dm13806Zvb8/S4xn3NTXPfq8zk3AACUPqb9nJub8V59AABgHxdHF2CPG92rX61atWzbpKWlKS0tzfr1mTNnirxOAADgOKUq3Ej236sfHh6uGTNmFHldKJiAiV84ugSH+Pul7o4uAcgTfkbzh3FzjFJ1WSo/9+pPmjRJqamp1ldSUlJxlAoAABykVM3ctGnTRp9//rlN243u1Xdzc5Obm1txlAcAAEoAh87ccK8+AAAobA6dudm+fbvuvvtu69dhYWGSpAEDBigmJkbJycnWoCNJgYGBWrduncaPH6833nhD1atX17x58/Twww8Xe+0AAKBkcmi4ueuuu5Tbx+zExMRka+vYsaN27txZhFUBAIDSrFQtKAYAALgRwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg1wk1m4cKECAwPl7u6uFi1aaPPmzbn2X7ZsmZo1ayZPT09Vq1ZNgwYN0smTJ63vr169WsHBwSpfvry8vLwUFBSk9957z2Yf4eHhatmypcqVK6cqVarogQce0L59+4rk/ACAcAPcRFasWKFx48Zp8uTJiouLU/v27dW1a1clJibm2P+HH35Q//79NWTIEP32229auXKltm3bpqFDh1r7VKxYUZMnT9aWLVv066+/atCgQRo0aJC+/vpra5/vv/9eo0aN0tatWxUbG6v09HSFhITo/PnzRX7OAG4+Lo4uAEDxiYiI0JAhQ6zhJDIyUl9//bUWLVqk8PDwbP23bt2qgIAAjR07VpIUGBioYcOGac6cOdY+d911l802Tz75pN555x398MMP6tKliyTpq6++sukTHR2tKlWqaMeOHerQoUNhniIAMHMD3CwuXbqkHTt2KCQkxKY9JCREP/30U47btG3bVocOHdK6detkGIaOHj2qjz/+WN27d8+xv2EY+vbbb7Vv375cQ0tqaqqkK7M+AFDYmLkBbhInTpxQRkaG/Pz8bNr9/PyUkpKS4zZt27bVsmXLFBoaqn///Vfp6enq2bOn5s+fb9MvNTVVNWrUUFpampydnbVw4UJ17tw5x30ahqGwsDDdeeedaty4ceGcHABchZkb4CZjsVhsvjYMI1tbloSEBI0dO1ZTp07Vjh079NVXX+nAgQMaPny4Tb9y5copPj5e27Zt04svvqiwsDBt3Lgxx32OHj1av/76q5YvX14o51NcCnsh9m+//aaHH35YAQEBslgsioyMzLaP9PR0TZkyRYGBgfLw8FCdOnU0c+ZMZWZmFvbpAaZCuCkhHPGL82rh4eGyWCwaN25cIZwNSqJKlSrJ2dk52yzNsWPHss3mZAkPD1e7du309NNPq2nTpurSpYsWLlyoqKgoJScnW/s5OTmpbt26CgoK0oQJE9S7d+8c1/CMGTNGa9as0XfffaeaNWsW7gkWoaJYiH3hwgXVqVNHL730kqpWrZrjfl5++WW9+eabWrBggfbu3as5c+bolVdeyTZzBsAW4aYEcNQvzizbtm3TW2+9paZNmxbqeaFkcXV1VYsWLRQbG2vTHhsbq7Zt2+a4zYULF+TkZPtrwtnZWdKVGZ/rMQxDaWlpNl+PHj1aq1ev1oYNGxQYGJjf03CIqxdiN2jQQJGRkapVq5YWLVqUY/+rF2IHBgbqzjvv1LBhw7R9+3Zrn5YtW+qVV15R37595ebmluN+tmzZol69eql79+4KCAhQ7969FRISYrMfANkRbkoAR/3ilKRz587pP//5j5YsWaIKFSoU+rmhZAkLC9PSpUsVFRWlvXv3avz48UpMTLReZpo0aZL69+9v7d+jRw+tXr1aixYt0v79+/Xjjz9q7NixuuOOO1S9enVJV2Z3YmNjtX//fv3++++KiIjQu+++q//+97/W/YwaNUrvv/++PvjgA5UrV04pKSlKSUnRxYsXi3cA8qE4FmJfz5133qlvv/1Wf/zxhyRp165d+uGHH9StW7f8nQxwk2BBsYNl/eKcOHGiTfuNfnFOnjxZ69atU9euXXXs2LF8/eKUrvzR6d69u+69917NmjUrX+eA0iM0NFQnT57UzJkzlZycrMaNG2vdunXy9/eXJCUnJ9vMGA4cOFBnz57VggULNGHCBJUvX1733HOPXn75ZWuf8+fPa+TIkTp06JA8PDxUv359vf/++woNDbX2yQrq1942Hh0drYEDBxbdCReColyIfSPPPvusUlNTVb9+fTk7OysjI0MvvviiHn300XyfD3AzINw4mCN/cX744YfauXOntm3blu/6UfqMHDlSI0eOzPG9mJiYbG1jxozRmDFjrru/WbNm3TAY53YJq7TI70LsLl26KDk5WU8//bSGDx+ut99+O8/HXLFihXXGq1GjRoqPj9e4ceNUvXp1DRgwoEDnA5gZ4aaEKO5fnElJSXryySe1fv16ubu7F7h+wKwKuhBbkpo2bSovLy+1b99es2bNUrVq1fJ07KeffloTJ05U3759JUlNmjTRwYMHFR4eTrgBcsGaGwcryjtYcrNjxw4dO3ZMLVq0kIuLi1xcXPT9999r3rx5cnFxUUZGRoHPDTCD4lyIndf9cCs4kDtmbhzs6l+cDz74oLU9NjZWvXr1ynGbCxcuyMXF9ltn7y/OTp06affu3TZtgwYNUv369fXss89a94eSK2DiF44uwWH+fsn+9WUFERYWpscee0zBwcFq06aN3nrrrWwLsQ8fPqx3331X0pWF2I8//rgWLVpknV0dN26czULsS5cuKSEhwfrfhw8fVnx8vMqWLau6deta9/Piiy+qdu3aatSokeLi4hQREaHBgwcX6/kDpQ3hpgRwxC/OcuXKZft0WC8vL/n6+vKpscA1imIh9pEjR9S8eXPr13PnztXcuXPVsWNH6wcgzp8/X88//7xGjhypY8eOqXr16ho2bJimTp1aPCcOlFKEmxLAUb84AeRdYS/EDggIuOFMa7ly5RQZGXnDD+EEYItwU0I44hfntQg9AAAzYEExAAAwFWZuANxUbtaF2MW9CBtwJMJNIeMXJwAAjuXwy1KF/TRsAABwc3NouCmKp2EDAICbm0PDTVE8DRsAANzcHBZusp6GHRISYtN+o6dhHzp0SOvWrZNhGDp69OgNn4adlpamM2fO2LwAAIB5OSzcFPRp2K6urqpatarKly+f69Oww8PD5ePjY33VqlWrUM8DAACULA5fUJzfp2Hv2LFDX331lQ4cOGB9TEFOJk2apNTUVOsrKSmpUOsHAAAli8NuBS/o07AlqWnTpvLy8lL79u01a9YsVatWLds2bm5ucnNzK/wTAAAAJZLDZm6ufhr21WJjY9W2bdsct7lw4YKcnGxLtvdp2AAAwNwcelkqLCxMS5cuVVRUlPbu3avx48dnexp2//79rf179Oih1atXa9GiRdq/f79+/PFHjR071uZp2AAA4Obm0E8oLoqnYQMAgJubwx+/UNhPwwYAADc3h98tBQAAUJgINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQcHm4WLlyowMBAubu7q0WLFtq8eXOu/dPS0jR58mT5+/vLzc1Nt9xyi6KiooqpWgAAUNK5OPLgK1as0Lhx47Rw4UK1a9dOixcvVteuXZWQkKDatWvnuE2fPn109OhRvf3226pbt66OHTum9PT0Yq4cAACUVHaHm4CAAA0ePFgDBw68bgDJq4iICA0ZMkRDhw6VJEVGRurrr7/WokWLFB4enq3/V199pe+//1779+9XxYoVrfUAAABksfuy1IQJE/TZZ5+pTp066ty5sz788EOlpaXZfeBLly5px44dCgkJsWkPCQnRTz/9lOM2a9asUXBwsObMmaMaNWrotttu01NPPaWLFy/afXwAAGBOdoebMWPGaMeOHdqxY4caNmyosWPHqlq1aho9erR27tyZ5/2cOHFCGRkZ8vPzs2n38/NTSkpKjtvs379fP/zwg/bs2aNPPvlEkZGR+vjjjzVq1KjrHictLU1nzpyxeQEAAPPK94LiZs2a6fXXX9fhw4c1bdo0LV26VC1btlSzZs0UFRUlwzDytB+LxWLztWEY2dqyZGZmymKxaNmyZbrjjjvUrVs3RUREKCYm5rqzN+Hh4fLx8bG+atWqZd+JAgCAUiXf4eby5cv66KOP1LNnT02YMEHBwcFaunSp+vTpo8mTJ+s///lPrttXqlRJzs7O2WZpjh07lm02J0u1atVUo0YN+fj4WNsaNGggwzB06NChHLeZNGmSUlNTra+kpCQ7zxQAAJQmdi8o3rlzp6Kjo7V8+XI5Ozvrscce02uvvab69etb+4SEhKhDhw657sfV1VUtWrRQbGysHnzwQWt7bGysevXqleM27dq108qVK3Xu3DmVLVtWkvTHH3/IyclJNWvWzHEbNzc3ubm52XuaAACglLJ75qZly5b6888/tWjRIh06dEhz5861CTaS1LBhQ/Xt2/eG+woLC9PSpUsVFRWlvXv3avz48UpMTNTw4cMlXZl16d+/v7V/v3795Ovrq0GDBikhIUGbNm3S008/rcGDB8vDw8PeUwEAACZk98zN/v375e/vn2sfLy8vRUdH33BfoaGhOnnypGbOnKnk5GQ1btxY69ats+4/OTlZiYmJ1v5ly5ZVbGysxowZo+DgYPn6+qpPnz6aNWuWvacBAABMyu5wc+zYMaWkpKhVq1Y27T///LOcnZ0VHBxs1/5GjhypkSNH5vheTExMtrb69esrNjbWrmMAAICbh92XpUaNGpXjotzDhw/neks2AABAcbA73CQkJOj222/P1t68eXMlJCQUSlEAAAD5ZXe4cXNz09GjR7O1Jycny8XFoY+qAgAAsD/cdO7c2frZMVlOnz6t5557Tp07dy7U4gAAAOxl91TLq6++qg4dOsjf31/NmzeXJMXHx8vPz0/vvfdeoRcIAABgD7vDTY0aNfTrr79q2bJl2rVrlzw8PDRo0CA9+uijKlOmTFHUCAAAkGf5WiTj5eWlJ554orBrAQAAKLB8rwBOSEhQYmKiLl26ZNPes2fPAhcFAACQX/n6hOIHH3xQu3fvlsVisT79O+tJ3hkZGYVbIQAAgB3svlvqySefVGBgoI4ePSpPT0/99ttv2rRpk4KDg7Vx48YiKBEAACDv7J652bJlizZs2KDKlSvLyclJTk5OuvPOOxUeHq6xY8cqLi6uKOoEAADIE7tnbjIyMlS2bFlJUqVKlXTkyBFJkr+/v/bt21e41QEAANjJ7pmbxo0b69dff1WdOnXUqlUrzZkzR66urnrrrbdUp06doqgRAAAgz+wON1OmTNH58+clSbNmzdL999+v9u3by9fXVytWrCj0AgEAAOxhd7jp0qWL9b/r1KmjhIQEnTp1ShUqVLDeMQUAAOAodq25SU9Pl4uLi/bs2WPTXrFiRYINAAAoEewKNy4uLvL39+ezbAAAQIll991SU6ZM0aRJk3Tq1KmiqAcAAKBA7F5zM2/ePP3vf/9T9erV5e/vLy8vL5v3d+7cWWjFAQAA2MvucPPAAw8UQRkAAACFw+5wM23atKKoAwAAoFDYveYGAACgJLN75sbJySnX2765kwoAADiS3eHmk08+sfn68uXLiouL0zvvvKMZM2YUWmEAAAD5YXe46dWrV7a23r17q1GjRlqxYoWGDBlSKIUBAADkR6GtuWnVqpW++eabwtodAABAvhRKuLl48aLmz5+vmjVrFsbuAAAA8s3uy1LXPiDTMAydPXtWnp6eev/99wu1OAAAAHvZHW5ee+01m3Dj5OSkypUrq1WrVqpQoUKhFgcAAGAvu8PNwIEDi6AMAACAwmH3mpvo6GitXLkyW/vKlSv1zjvvFEpRAAAA+WV3uHnppZdUqVKlbO1VqlTR7NmzC6UoAACA/LI73Bw8eFCBgYHZ2v39/ZWYmFgoRQEAAOSX3eGmSpUq+vXXX7O179q1S76+voVSFAAAQH7ZHW769u2rsWPH6rvvvlNGRoYyMjK0YcMGPfnkk+rbt29R1AgAAJBndt8tNWvWLB08eFCdOnWSi8uVzTMzM9W/f3/W3AAAAIezO9y4urpqxYoVmjVrluLj4+Xh4aEmTZrI39+/KOoDAACwi93hJsutt96qW2+9tTBrAQAAKDC719z07t1bL730Urb2V155RY888kihFAUAAJBfdoeb77//Xt27d8/Wft9992nTpk2FUhQAAEB+2R1uzp07J1dX12ztZcqU0ZkzZwqlKAAAgPyyO9w0btxYK1asyNb+4YcfqmHDhoVSFAAAQH7ZvaD4+eef18MPP6y//vpL99xzjyTp22+/1QcffKCPP/640AsEAACwh93hpmfPnvr00081e/Zsffzxx/Lw8FCzZs20YcMGeXt7F0WNAAAAeZavW8G7d+9uXVR8+vRpLVu2TOPGjdOuXbuUkZFRqAUCAADYw+41N1k2bNig//73v6pevboWLFigbt26afv27YVZGwAAgN3smrk5dOiQYmJiFBUVpfPnz6tPnz66fPmyVq1axWJiAABQIuR55qZbt25q2LChEhISNH/+fB05ckTz588vytoAAADslueZm/Xr12vs2LEaMWIEj10AAAAlVp5nbjZv3qyzZ88qODhYrVq10oIFC3T8+PGirA0AAMBueQ43bdq00ZIlS5ScnKxhw4bpww8/VI0aNZSZmanY2FidPXu2KOsEAADIE7vvlvL09NTgwYP1ww8/aPfu3ZowYYJeeuklValSRT179iyKGgEAAPIs37eCS1K9evU0Z84cHTp0SMuXLy+smgAAAPKtQOEmi7Ozsx544AGtWbOmMHYHAACQb4USbgAAAEoKwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVh4ebhQsXKjAwUO7u7mrRooU2b96cp+1+/PFHubi4KCgoqGgLBAAApYpDw82KFSs0btw4TZ48WXFxcWrfvr26du2qxMTEXLdLTU1V//791alTp2KqFAAAlBYODTcREREaMmSIhg4dqgYNGigyMlK1atXSokWLct1u2LBh6tevn9q0aVNMlQIAgNLCYeHm0qVL2rFjh0JCQmzaQ0JC9NNPP113u+joaP3111+aNm1ano6TlpamM2fO2LwAAIB5OSzcnDhxQhkZGfLz87Np9/PzU0pKSo7b/Pnnn5o4caKWLVsmFxeXPB0nPDxcPj4+1letWrUKXDsAACi5HL6g2GKx2HxtGEa2NknKyMhQv379NGPGDN1222153v+kSZOUmppqfSUlJRW4ZgAAUHLlbfqjCFSqVEnOzs7ZZmmOHTuWbTZHks6ePavt27crLi5Oo0ePliRlZmbKMAy5uLho/fr1uueee7Jt5+bmJjc3t6I5CQAAUOI4bObG1dVVLVq0UGxsrE17bGys2rZtm62/t7e3du/erfj4eOtr+PDhqlevnuLj49WqVaviKh0AAJRgDpu5kaSwsDA99thjCg4OVps2bfTWW28pMTFRw4cPl3TlktLhw4f17rvvysnJSY0bN7bZvkqVKnJ3d8/WDgAAbl4ODTehoaE6efKkZs6cqeTkZDVu3Fjr1q2Tv7+/JCk5OfmGn3kDAABwNYeGG0kaOXKkRo4cmeN7MTExuW47ffp0TZ8+vfCLAgAApZbD75YCAAAoTIQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKg4PNwsXLlRgYKDc3d3VokULbd68+bp9V69erc6dO6ty5cry9vZWmzZt9PXXXxdjtQAAoKRzaLhZsWKFxo0bp8mTJysuLk7t27dX165dlZiYmGP/TZs2qXPnzlq3bp127Nihu+++Wz169FBcXFwxVw4AAEoqh4abiIgIDRkyREOHDlWDBg0UGRmpWrVqadGiRTn2j4yM1DPPPKOWLVvq1ltv1ezZs3Xrrbfq888/L+bKAQBASeWwcHPp0iXt2LFDISEhNu0hISH66aef8rSPzMxMnT17VhUrVrxun7S0NJ05c8bmBQAAzMth4ebEiRPKyMiQn5+fTbufn59SUlLytI9XX31V58+fV58+fa7bJzw8XD4+PtZXrVq1ClQ3AAAo2Ry+oNhisdh8bRhGtracLF++XNOnT9eKFStUpUqV6/abNGmSUlNTra+kpKQC1wwAAEouF0cduFKlSnJ2ds42S3Ps2LFssznXWrFihYYMGaKVK1fq3nvvzbWvm5ub3NzcClwvAAAoHRw2c+Pq6qoWLVooNjbWpj02NlZt27a97nbLly/XwIED9cEHH6h79+5FXSYAAChlHDZzI0lhYWF67LHHFBwcrDZt2uitt95SYmKihg8fLunKJaXDhw/r3XfflXQl2PTv31+vv/66WrdubZ318fDwkI+Pj8POAwAAlBwODTehoaE6efKkZs6cqeTkZDVu3Fjr1q2Tv7+/JCk5OdnmM28WL16s9PR0jRo1SqNGjbK2DxgwQDExMcVdPgAAKIEcGm4kaeTIkRo5cmSO710bWDZu3Fj0BQEAgFLN4XdLAQAAFCbCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBWHh5uFCxcqMDBQ7u7uatGihTZv3pxr/++//14tWrSQu7u76tSpozfffLOYKgUAAKWBQ8PNihUrNG7cOE2ePFlxcXFq3769unbtqsTExBz7HzhwQN26dVP79u0VFxen5557TmPHjtWqVauKuXIAAFBSOTTcREREaMiQIRo6dKgaNGigyMhI1apVS4sWLcqx/5tvvqnatWsrMjJSDRo00NChQzV48GDNnTu3mCsHAAAllcPCzaVLl7Rjxw6FhITYtIeEhOinn37KcZstW7Zk69+lSxdt375dly9fLrJaAQBA6eHiqAOfOHFCGRkZ8vPzs2n38/NTSkpKjtukpKTk2D89PV0nTpxQtWrVsm2TlpamtLQ069epqamSpDNnzhT0FHKUmXahSPZb0hV0PBk3+92sYyYxbvnBz2j+MG75UxR/Y7P2aRjGDfs6LNxksVgsNl8bhpGt7Ub9c2rPEh4erhkzZmRrr1Wrlr2lIhc+kY6uoHRi3PKHcbMfY5Y/jFv+FOW4nT17Vj4+Prn2cVi4qVSpkpydnbPN0hw7dizb7EyWqlWr5tjfxcVFvr6+OW4zadIkhYWFWb/OzMzUqVOn5Ovrm2uIKm3OnDmjWrVqKSkpSd7e3o4up9Rg3PKHcbMfY5Y/jFv+mHHcDMPQ2bNnVb169Rv2dVi4cXV1VYsWLRQbG6sHH3zQ2h4bG6tevXrluE2bNm30+eef27StX79ewcHBKlOmTI7buLm5yc3NzaatfPnyBSu+BPP29jbNP+TixLjlD+NmP8Ysfxi3/DHbuN1oxiaLQ++WCgsL09KlSxUVFaW9e/dq/PjxSkxM1PDhwyVdmXXp37+/tf/w4cN18OBBhYWFae/evYqKitLbb7+tp556ylGnAAAAShiHrrkJDQ3VyZMnNXPmTCUnJ6tx48Zat26d/P39JUnJyck2n3kTGBiodevWafz48XrjjTdUvXp1zZs3Tw8//LCjTgEAAJQwDl9QPHLkSI0cOTLH92JiYrK1dezYUTt37iziqkofNzc3TZs2LdslOOSOccsfxs1+jFn+MG75c7OPm8XIyz1VAAAApYTDny0FAABQmAg3AADAVAg3AADAVAg3N4GNGzfKYrHo9OnTji6lVGHc7MeY5Q/jlj+MW/7cDONGuCliAwcOlMVikcVikYuLi2rXrq0RI0bon3/+cVhNMTExefogw+TkZPXr10/16tWTk5OTxo0bV+S1ZSnN47Z69Wp17txZlStXlre3t9q0aaOvv/66yOsrzWP2ww8/qF27dvL19ZWHh4fq16+v1157regLVOket6v9+OOPcnFxUVBQUJHUdK3SPG5Zf9yvff3+++9FXmNpHjfpyvMaJ0+eLH9/f7m5uemWW25RVFRU0RaYDw6/FfxmcN999yk6Olrp6elKSEjQ4MGDdfr0aS1fvtzRpeUqLS1NlStX1uTJk4vtD83VSuu4bdq0SZ07d9bs2bNVvnx5RUdHq0ePHvr555/VvHnzIj12aR0zLy8vjR49Wk2bNpWXl5d++OEHDRs2TF5eXnriiSeK/PilddyypKamqn///urUqZOOHj1abMct7eO2b98+m0/vrVy5crEctzSPW58+fXT06FG9/fbbqlu3ro4dO6b09HRHl5WdgSI1YMAAo1evXjZtYWFhRsWKFW3aoqKijPr16xtubm5GvXr1jDfeeMP6XlpamjFq1CijatWqhpubm+Hv72/Mnj3bMAzDOHDggCHJiIuLs/b/559/DEnGd999ZxiGYXz33XeGJOOff/6x/vfVr2nTpt3wPDp27Gg8+eST+RmCfDHLuGVp2LChMWPGDLvGwF5mG7MHH3zQ+O9//2vXGOSHGcYtNDTUmDJlijFt2jSjWbNm+R0Ku5Tmcbt6u+JWmsftyy+/NHx8fIyTJ08WeByKGjM3xWz//v366quvbJ6FtWTJEk2bNk0LFixQ8+bNFRcXp8cff1xeXl4aMGCA5s2bpzVr1uijjz5S7dq1lZSUpKSkpHwdv23btoqMjNTUqVO1b98+SVLZsmUL5dyKUmket8zMTJ09e1YVK1bM17HzqzSPWVxcnH766SfNmjUrX8cuiNI2btHR0frrr7/0/vvvO2S8spS2cZOk5s2b699//1XDhg01ZcoU3X333fk6dkGUpnFbs2aNgoODNWfOHL333nvy8vJSz5499cILL8jDwyNfxy8qhJtisHbtWpUtW1YZGRn6999/JUkRERHW91944QW9+uqreuihhyRdecxEQkKCFi9erAEDBigxMVG33nqr7rzzTlksFuvjKfLD1dVVPj4+slgsqlq1asFOrIiZZdxeffVVnT9/Xn369Mn38fOqtI9ZzZo1dfz4caWnp2v69OkaOnRovo9vj9I6bn/++acmTpyozZs3y8Wl+H+dl9Zxq1atmt566y21aNFCaWlpeu+999SpUydt3LhRHTp0yHcNeVVax23//v364Ycf5O7urk8++UQnTpzQyJEjderUqRK37oZwUwzuvvtuLVq0SBcuXNDSpUv1xx9/aMyYMZKk48ePKykpSUOGDNHjjz9u3SY9Pd369NOBAweqc+fOqlevnu677z7df//9CgkJcci5FCczjNvy5cs1ffp0ffbZZ6pSpUqRH6+0j9nmzZt17tw5bd26VRMnTlTdunX16KOPFvlxS+O4ZWRkqF+/fpoxY4Zuu+22Ij3W9ZTGcZOkevXqqV69etav27Rpo6SkJM2dO7dYwk1pHbfMzExZLBYtW7bMWktERIR69+6tN954o0TN3nC3VDHw8vJS3bp11bRpU82bN09paWmaMWOGpCv/WKQr05Dx8fHW1549e7R161ZJ0u23364DBw7ohRde0MWLF9WnTx/17t1bkuTkdOVbaFz1FI3Lly8X5+kVmdI+bitWrNCQIUP00Ucf6d577y3UfV9PaR+zwMBANWnSRI8//rjGjx+v6dOnF+r+r6c0jtvZs2e1fft2jR49Wi4uLnJxcdHMmTO1a9cuubi4aMOGDQU+xo2UxnG7ntatW+vPP/8ssv1frbSOW7Vq1VSjRg1rsJGkBg0ayDAMHTp0qFCOUViYuXGAadOmqWvXrhoxYoSqV6+uGjVqaP/+/frPf/5z3W28vb0VGhqq0NBQ9e7dW/fdd59OnTplXd2fnJxsvRMnPj4+1+O7uroqIyOj0M6nuJSmcVu+fLkGDx6s5cuXq3v37nk7wSJQmsbsWoZhKC0tLV/bFlRpGDdvb2/t3r3bpm3hwoXasGGDPv74YwUGBubhTAtXaRi364mLi1O1atXytW1BlZZxa9eunVauXKlz585Z1+X88ccfcnJyUs2aNfN4tsWDcOMAd911lxo1aqTZs2drwYIFmj59usaOHStvb2917dpVaWlp2r59u/755x+FhYXptddeU7Vq1RQUFCQnJyetXLlSVatWVfny5eXk5KTWrVvrpZdeUkBAgE6cOKEpU6bkevyAgACdO3dO3377rZo1ayZPT095enrm2Dfrh+LcuXM6fvy44uPj5erqqoYNGxb2sNxQaRm35cuXq3///nr99dfVunVrpaSkSJI8PDxs/o+nOJSWMXvjjTdUu3Zt1a9fX9KVz72ZO3eudaq+uJWGcXNyclLjxo1t2qpUqSJ3d/ds7cWlNIybJEVGRiogIECNGjXSpUuX9P7772vVqlVatWpVUQ1NrkrLuPXr108vvPCCBg0apBkzZujEiRN6+umnNXjw4BJ1SUoSt4IXtZxu+zMMw1i2bJnh6upqJCYmWr8OCgoyXF1djQoVKhgdOnQwVq9ebRiGYbz11ltGUFCQ4eXlZXh7exudOnUydu7cad1XQkKC0bp1a8PDw8MICgoy1q9ff93b/rIMHz7c8PX1veFtprrmFkFJhr+/f0GH5YZK87h17Ngxx3EbMGBAYQzNdZXmMZs3b57RqFEjw9PT0/D29jaaN29uLFy40MjIyCiUsclNaR63azn6VnDDKB3j9vLLLxu33HKL4e7ublSoUMG48847jS+++KJQxuVGSvO4GYZh7N2717j33nsNDw8Po2bNmkZYWJhx4cKFAo9LYbMYxlUX5gAAAEo5FhQDAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAKPU2btwoi8Wi06dP27Xd9OnTFRQUZP164MCBeuCBBwq1NgDFj3ADoEAGDhwoi8Uii8UiFxcX1a5dWyNGjNA///zjsJpiYmJUvnx5u7d7/fXXFRMTk6e+BCGg5OLZUgAK7L777lN0dLTS09OVkJCgwYMH6/Tp01q+fLmjS7NLcT/7C0DRYOYGQIG5ubmpatWqqlmzpkJCQhQaGqr169fb9ImOjlaDBg3k7u6u+vXra+HChdb3Ll26pNGjR6tatWpyd3dXQECAwsPDJUl///23LBaLzZONT58+LYvFoo0bN2arZePGjRo0aJBSU1OtM0rTp0/P03lcOxvz8ccfq0mTJvLw8JCvr6/uvfdenT9/XtOnT9c777yjzz77zHqMjRs35noeAIoPMzcACtX+/fv11VdfqUyZMta2JUuWaNq0aVqwYIGaN2+uuLg4Pf744/Ly8tKAAQM0b948rVmzRh999JFq166tpKQkJSUl5ev4bdu2VWRkpKZOnap9+/ZJksqWLWv3fpKTk/Xoo49qzpw5evDBB3X27Flt3rxZhmHoqaee0t69e3XmzBlFR0dLkipWrFio5wEg/wg3AAps7dq1Klu2rDIyMvTvv/9KkiIiIqzvv/DCC3r11Vf10EMPSZICAwOVkJCgxYsXa8CAAUpMTNStt96qO++8UxaLRf7+/vmuxdXVVT4+PrJYLKpatWq+95OcnKz09HQ99NBD1nqaNGlifd/Dw0NpaWk2xyjM8wCQf1yWAlBgd999t+Lj4/Xzzz9rzJgx6tKli8aMGSNJOn78uJKSkjRkyBCVLVvW+po1a5b++usvSVcuB8XHx6tevXoaO3ZstktajtCsWTN16tRJTZo00SOPPKIlS5bccJF0STwP4GZEuAFQYF5eXqpbt66aNm2qefPmKS0tTTNmzJAkZWZmSrpyaSo+Pt762rNnj7Zu3SpJuv3223XgwAG98MILunjxovr06aPevXtLkpycrvyaMgzDerzLly8X+Tk5OzsrNjZWX375pRo2bKj58+erXr16OnDgwHW3ye08ABQfwg2AQjdt2jTNnTtXR44ckZ+fn2rUqKH9+/erbt26Nq/AwEDrNt7e3goNDdWSJUu0YsUKrVq1SqdOnVLlypUlXblMlOXqxcU5cXV1VUZGRoHPw2KxqF27dpoxY4bi4uLk6uqqTz75JNdjXO88ABQf1twAKHR33XWXGjVqpNmzZ2vBggWaPn26xo4dK29vb3Xt2lVpaWnavn27/vnnH4WFhem1115TtWrVFBQUJCcnJ61cuVJVq1ZV+fLl5eTkpNatW+ull15SQECATpw4oSlTpuR6/ICAAJ07d07ffvutmjVrJk9PT3l6etp1Dj///LO+/fZbhYSEqEqVKvr55591/PhxNWjQwHqMr7/+Wvv27ZOvr698fHy0YMGC654HgOLDzA2AIhEWFqYlS5YoKSlJQ4cO1dKlSxUTE6MmTZqoY8eOiomJsc7clC1bVi+//LKCg4PVsmVL/f3331q3bp31klRUVJQuX76s4OBgPfnkk5o1a1aux27btq2GDx+u0NBQVa5cWXPmzLG7fm9vb23atEndunXTbbfdpilTpujVV19V165dJUmPP/646tWrp+DgYFWuXFk//vjjDc8DQPGwGFdfyAYAACjl+N8JAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKv8PWeu1SKUpmz4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = ['Result 1', 'Result 2', 'Result 3', 'Result 4', 'Result 5', 'Result 6']\n",
    "values = [sc1, sc2, sc3, sc4, sc5, sc6]\n",
    "\n",
    "# Create the bar graph\n",
    "plt.bar(labels, values)\n",
    "for i, value in enumerate(values):\n",
    "    plt.text(i, value, str(value), ha='center', va='bottom')\n",
    "# Add a title and labels\n",
    "plt.title('Bar Graph of Six Test Cases')\n",
    "plt.xlabel('Result lists')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "# Display the graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e178c401",
   "metadata": {},
   "source": [
    "In our multi-class classification task, it's crucial to evaluate our model's performance from two angles: micro and macro averages on precision and recall. The micro-average considers all classes collectively, essentially treating the problem as a binary classification task and giving equal weight to each instance. On the other hand, the macro-average treats each class independently and then averages the results, not taking into account any class imbalances. The key difference lies in their sensitivity to class imbalances. The micro-average can be influenced by the majority class, while the macro-average treats all classes equally. Analyzing these different averages helps us understand how well our model performs overall and how it handles individual classes, enabling us to make more informed decisions about our multi-class classification results.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38486a64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
